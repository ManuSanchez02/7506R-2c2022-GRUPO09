{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuracion Inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuWAbUfty0_V",
        "outputId": "d1b00949-e79a-4f1c-eafa-5ceab24938ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "dataset = pd.read_csv(\"../datasets/properati_argentina_2021.csv\")\n",
        "sns.set()\n",
        "\n",
        "SEMILLA = 0\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "\n",
        "def obtener_frecuencia_relativa(series):\n",
        "    frecuencia_absoluta = series.value_counts()\n",
        "    frecuencia_relativa = frecuencia_absoluta / frecuencia_absoluta.sum()\n",
        "    return frecuencia_relativa\n",
        "\n",
        "\n",
        "def separate_date(dataset, column_name):\n",
        "    dataset[f\"{column_name}_year\"] = dataset[column_name].str[:4].astype(int)\n",
        "    dataset[f\"{column_name}_month\"] = dataset[column_name].str[5:7].astype(int)\n",
        "    dataset[f\"{column_name}_day\"] = dataset[column_name].str[8:10].astype(int)\n",
        "    dataset.drop([column_name], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8edHYLM0aEo"
      },
      "source": [
        "# 1. Análisis Exploratorio y Preprocesamiento de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Separacion Train-Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train, dataset_test = train_test_split(\n",
        "    dataset, test_size=TEST_SIZE, random_state=SEMILLA\n",
        ")\n",
        "\n",
        "print(\"Proporcion - Train:\", dataset_train.shape[0] / dataset.shape[0])\n",
        "print(\"Proporcion - Test:\", dataset_test.shape[0] / dataset.shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filtrado del set de Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Damos un primer vistazo al dataset, para observar las columnas y sus valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW4w811s1HSS",
        "outputId": "7f3f86de-d86c-452b-9acd-3e2cb1b2148c"
      },
      "outputs": [],
      "source": [
        "dataset_train.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos un diccionario de filtros que vamos a utilizar para filtrar nuestro dataset, y filtramos las columnas que no nos interesan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp2YYu6s0zG4",
        "outputId": "42528409-c9c4-4756-f6f6-e9f6630aecc0"
      },
      "outputs": [],
      "source": [
        "filtro_tipo_propiedad = [\"casa\", \"ph\", \"departamento\"]\n",
        "filtro_operacion = [\"venta\"]\n",
        "filtro_ubicacion = [\"capital federal\"]\n",
        "filtro_moneda = [\"usd\"]\n",
        "\n",
        "filtros = {\n",
        "    \"property_type\": filtro_tipo_propiedad,\n",
        "    \"operation\": filtro_operacion,\n",
        "    \"place_l2\": filtro_ubicacion,\n",
        "    \"property_currency\": filtro_moneda,\n",
        "}\n",
        "\n",
        "\n",
        "for columna in filtros:\n",
        "    dataset_train[columna] = dataset_train[columna].str.lower()\n",
        "\n",
        "for columna_a_filtrar, filtro in filtros.items():\n",
        "    dataset_train = dataset_train[dataset_train[columna_a_filtrar].isin(filtro)]\n",
        "\n",
        "dataset_train.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos la composicion de datos NULL en las columnas del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filas_totales = dataset_train.shape[0]\n",
        "dataset_train.isna().sum() / filas_totales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFR4QMRX6ZyH"
      },
      "source": [
        "Las columnas `place_l5` y `place_l6` contienen `NaN` en todas sus filas. Ademas, `place_4` contiene `NaN` en el 96% de sus filas. Por estas razones, eliminamos las columnas.\n",
        "\n",
        "Las columnas `id` y `property_title` no nos sirves para predecir nada, ya que son valores arbitrarios que no aportan al analisis. Por esta razon, las eliminamos tambien.\n",
        "\n",
        "Las `property_currency`, `place_l2`, `operation` solo contienen un valor posible debido al filtrado, por esto las eliminamos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "YjCKriS_6k_m",
        "outputId": "31cf7bcd-bf6a-40d5-aa46-fbc00444e2b2"
      },
      "outputs": [],
      "source": [
        "columnas_eliminar = [\n",
        "    \"property_title\",\n",
        "    \"id\",\n",
        "    \"place_l4\",\n",
        "    \"place_l5\",\n",
        "    \"place_l6\",\n",
        "    \"property_currency\",\n",
        "    \"operation\",\n",
        "    \"place_l2\",\n",
        "]\n",
        "dataset_train.drop(columnas_eliminar, axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`place_l3` no es un nombre muy significativo, lo renombramos a `barrio`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train = dataset_train.rename(columns={\"place_l3\": \"barrio\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convertimos las fechas en un mejor formato para el analisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "dataset_train[\"start_date\"] = pd.to_datetime(\n",
        "    dataset_train[\"start_date\"], errors=\"coerce\"\n",
        ")\n",
        "dataset_train[\"end_date\"] = pd.to_datetime(dataset_train[\"end_date\"], errors=\"coerce\")\n",
        "dataset_train[\"created_on\"] = pd.to_datetime(\n",
        "    dataset_train[\"created_on\"], errors=\"coerce\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpqg9SG980Ll"
      },
      "source": [
        "## Analisis Exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analisis Inicial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos la estructura general del dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Separamos el dataset en variables cualitativas, cuantitativas, y temporales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Zt4f5lXJ8vmB",
        "outputId": "3855e8f6-0fc8-4bea-bac4-ea7775921cc9"
      },
      "outputs": [],
      "source": [
        "columnas_cuantitativas = [\n",
        "    \"latitud\",\n",
        "    \"longitud\",\n",
        "    \"property_rooms\",\n",
        "    \"property_bedrooms\",\n",
        "    \"property_surface_total\",\n",
        "    \"property_surface_covered\",\n",
        "    \"property_price\",\n",
        "]\n",
        "variables_cuantitativas = dataset_train[columnas_cuantitativas]\n",
        "variables_cuantitativas.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_temporales = [\n",
        "    \"start_date\",\n",
        "    \"end_date\",\n",
        "    \"created_on\",\n",
        "]\n",
        "variables_temporales = dataset_train[columnas_temporales]\n",
        "variables_temporales.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_cualitativas = [\"barrio\", \"property_type\"]\n",
        "variables_cualitativas = dataset_train[columnas_cualitativas]\n",
        "variables_cualitativas.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables Cuantitativas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generamos estadisticas descriptivas para las columnas cuantitativas (medidas de resumen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "variables_cuantitativas.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos un mapa de correlaciones de las variables cuantitativas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "matriz_correlaciones = variables_cuantitativas.corr()\n",
        "sns.heatmap(data=matriz_correlaciones, annot=True, fmt=\".2f\", vmin=-1, vmax=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que las variables con mas relacionadas son:\n",
        " - `property_rooms` con `property_bedrooms`\n",
        " - `property_surface_covered` con `property_surface_total`.\n",
        " - `property_price` con `property_rooms` y `property_bedrooms` (con un porcentaje mucho menor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos graficos para observar estas relaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes = np.ndarray.flatten(axes)\n",
        "\n",
        "correlaciones = (\n",
        "    (\"property_rooms\", \"property_bedrooms\"),\n",
        "    (\"property_surface_covered\", \"property_surface_total\"),\n",
        "    (\"property_price\", \"property_rooms\"),\n",
        "    (\"property_price\", \"property_bedrooms\"),\n",
        ")\n",
        "for (i, correlacion) in enumerate(correlaciones):\n",
        "    sns.scatterplot(ax=axes[i], data=dataset_train, x=correlacion[0], y=correlacion[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vimos que hay cierta relacion lineal, pero es afectada por el alto numero de valores atipicos. Si los eliminamos rapidamente, el grafico cambia drasticamente. \n",
        "\n",
        "Graficamos con un _alpha_ para observar mejor la distribución"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas = (\n",
        "    \"property_surface_covered\",\n",
        "    \"property_surface_total\",\n",
        "    \"property_rooms\",\n",
        "    \"property_bedrooms\",\n",
        "    \"property_price\",\n",
        ")\n",
        "sin_atipicos = dataset_train.copy()\n",
        "for columna in columnas:\n",
        "    sin_atipicos = sin_atipicos[\n",
        "        sin_atipicos[columna] < sin_atipicos[columna].quantile(0.75) * 3.5\n",
        "    ]\n",
        "\n",
        "\n",
        "figs, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes = np.ndarray.flatten(axes)\n",
        "for (i, correlacion) in enumerate(correlaciones):\n",
        "    sns.scatterplot(ax=axes[i], data=sin_atipicos, x=correlacion[0], y=correlacion[1], alpha=0.05)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables Cualitativas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos la cantidad de valores posibles de cada variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_cualitativas.nunique()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribucion de los barrios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "NrQMh6g99Ktg",
        "outputId": "0ac2dc2c-25b4-4982-eedc-153a115cd07b"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n",
        "    nrows=1, ncols=2, figsize=(15, 5), gridspec_kw={\"width_ratios\": [3, 1]}\n",
        ")\n",
        "\n",
        "frecuencia_relativa = obtener_frecuencia_relativa(variables_cualitativas[\"barrio\"])\n",
        "ax = sns.barplot(ax=axes[0], x=frecuencia_relativa.index, y=frecuencia_relativa.values)\n",
        "ax.set(title=\"Distribucion de barrios\", xlabel=\"barios\", ylabel=\"frecuencia\")\n",
        "ax.tick_params(\"x\", labelrotation=90)\n",
        "\n",
        "frecuencia_relativa = obtener_frecuencia_relativa(\n",
        "    variables_cualitativas[\"property_type\"]\n",
        ")\n",
        "ax = sns.barplot(ax=axes[1], x=frecuencia_relativa.index, y=frecuencia_relativa.values)\n",
        "ax.set(\n",
        "    title=\"Distribucion del tipo de propiedad\",\n",
        "    xlabel=\"tipo de propiedad\",\n",
        "    ylabel=\"frecuencia\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables Temporales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribución de las variables temporales\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
        "\n",
        "for ax in axes:\n",
        "    ax.tick_params(\"x\", labelrotation=90)\n",
        "\n",
        "sns.histplot(ax=axes[0], data=variables_temporales, x=\"start_date\", stat=\"density\").set(\n",
        "    title=\"Distribucion de fecha de inicio\"\n",
        ")\n",
        "sns.histplot(ax=axes[1], data=variables_temporales, x=\"end_date\", stat=\"density\").set(\n",
        "    title=\"Distribucion de fecha de finalizacion\"\n",
        ")\n",
        "sns.histplot(ax=axes[2], data=variables_temporales, x=\"created_on\", stat=\"density\").set(\n",
        "    title=\"Distribucion de fecha de creacion\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos eliminar `created_on`, ya que tiene distribucion practicamente identica a `start_date`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisis de Valores Atipicos (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SOLO PARA PROBAR - ACTUALIZAR CON VERDADERO ANALISIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for columna in variables_cuantitativas.columns:\n",
        "    filtro_columna = dataset_train[columna] > dataset_train[columna].quantile(0.99)\n",
        "    dataset_train[columna] = dataset_train[columna].mask(filtro_columna, np.NaN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisis de datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribucion de datos nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cantidad_de_datos_nulos_por_columna = dataset_train.isna().sum()\n",
        "frecuencia_relativa = cantidad_de_datos_nulos_por_columna / dataset_train.shape[0]\n",
        "frecuencia_relativa = frecuencia_relativa[frecuencia_relativa.values != 0]\n",
        "frecuencia_relativa = frecuencia_relativa.sort_values(ascending=False)\n",
        "\n",
        "ax = sns.barplot(x=frecuencia_relativa.index, y=frecuencia_relativa.values)\n",
        "ax.set(\n",
        "    title=\"distribucion de datos faltantes por columna\",\n",
        "    xlabel=\"columna\",\n",
        "    ylabel=\"distribucion\",\n",
        ")\n",
        "ax.tick_params(\"x\", labelrotation=90)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribucion de cantidad de datos faltantes por fila. \n",
        "\n",
        "Vemos que la cantidad de filas con mas de 3 datos faltantes es minima\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "distribucion_faltantes_por_fila = (\n",
        "    dataset_train.isna().sum(axis=1).value_counts() / dataset_train.shape[0]\n",
        ")\n",
        "ax = sns.barplot(\n",
        "    x=distribucion_faltantes_por_fila.index,\n",
        "    y=distribucion_faltantes_por_fila.values,\n",
        ")\n",
        "ax.set(\n",
        "    xlabel=\"Cantidad de datos faltantes por fila\",\n",
        "    ylabel=\"proporcion\",\n",
        "    title=\"proporcion de datos faltantes por fila\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputacion de datos faltante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algunas estrategias para imputar los datos faltantes:\n",
        "\n",
        "- Sustitución de Casos: Se reemplaza con valores no observados. Hay que consultar con un experto.\n",
        "- Sustitución por Media: Se reemplaza utilizando la medida calculada de los valores presentes. Sin embargo, esto trae consecuencias\n",
        "    - La varianza estimada por la nueva variable no es válida ya que es atenuada por los valores repetidos\n",
        "    - Se distorsiona la distribución\n",
        "    - Las correlaciones que se observen estaran deprimidas debido a la repetición de un solo valores constante.\n",
        "- Imputación Cold Deck: Se pueden obtener los datos faltantes a partir de otras variables del dataset.\n",
        "- Imputacion Hot Deck: Se reemplazan los datos faltante con los valores que resultan más “similares”. Tenemos que definir que es “similar”, para ello se puede usar la tecnica: K vecinos más cercanos.\n",
        "- Imputación por Regresión: El dato faltante es reemplaza con el valor predicho por un modelo de regresión.\n",
        "- MICE (multivariate imputation by chained equations): Trabaja bajo el supuesto de que el origen de los datos es MAR (missing at random). Es un proceso de imputación iterativo, donde cada iteración los valores faltantes se predicen en función de las variables restantes. El proceso se repite hasta que se encuentre consistencia en los datos (usualmente 10 iteraciones es suficiente). La primera iteración se realiza por uno de los métodos vistos anteriormente para rellenar los datos faltantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputacion `property_bedrooms`, `property_rooms`, `property_price`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anteriormente observamos que hay una correlacion entre `property_bedrooms`, `property_rooms` y `property_price`. Podemos entrenar un modelo lineal para predecir los datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imputamos los datos utilizando un imputador iterativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_a_imputar = [\"property_bedrooms\", \"property_rooms\", \"property_price\"]\n",
        "\n",
        "modelo_lineal = LinearRegression()\n",
        "imp = IterativeImputer(\n",
        "    estimator=modelo_lineal,\n",
        "    missing_values=np.nan,\n",
        "    max_iter=20,\n",
        "    random_state=SEMILLA,\n",
        ")\n",
        "\n",
        "columnas_imputadas = imp.fit_transform(dataset_train[columnas_a_imputar])\n",
        "\n",
        "dataset_imputado = pd.DataFrame(columnas_imputadas, columns=columnas_a_imputar).astype(\n",
        "    int\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que tienen la misma distribución que los datos originales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 16))\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[0][0], x=dataset_train.property_rooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(title=\"distribucion de cantidad de cuartos\", xlabel=\"cantidad de cuartos\")\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[0][1], x=dataset_train.property_bedrooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(title=\"distribucion de cantidad de baños\", xlabel=\"cantidad de baños\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[0][2], x=dataset_train.property_price)\n",
        "ax.set(title=\"distribucion de precio de propiedad\", xlabel=\"precio de propiedad\")\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[1][0], x=dataset_imputado.property_rooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(\n",
        "    title=\"distribucion de cantidad de cuartos (imputado)\", xlabel=\"cantidad de cuartos\"\n",
        ")\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[1][1], x=dataset_imputado.property_bedrooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(title=\"distribucion de cantidad de baños (imputado)\", xlabel=\"cantidad de baños\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[1][2], x=dataset_imputado.property_price)\n",
        "ax.set(\n",
        "    title=\"distribucion de precio de propiedad (imputado)\", xlabel=\"precio de propiedad\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actualizamos los valores imputados en el nuevo dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train[columnas_a_imputar] = dataset_imputado[columnas_a_imputar].values\n",
        "\n",
        "dataset_train.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputacion `property_surface_covered`, `property_surface_total`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tambien observamos que hay una correlacion entre `property_surface_covered`, `property_surface_total`. Podemos entrenar otro modelo lineal para predecir estos datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imputamos los datos utilizando un imputador iterativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_a_imputar = [\"property_surface_covered\", \"property_surface_total\"]\n",
        "\n",
        "modelo_lineal = LinearRegression()\n",
        "imp = IterativeImputer(\n",
        "    estimator=modelo_lineal,\n",
        "    missing_values=np.nan,\n",
        "    max_iter=20,\n",
        "    verbose=0,\n",
        "    random_state=SEMILLA,\n",
        ")\n",
        "\n",
        "columnas_imputadas = imp.fit_transform(dataset_train[columnas_a_imputar])\n",
        "\n",
        "dataset_imputado = pd.DataFrame(columnas_imputadas, columns=columnas_a_imputar).astype(\n",
        "    int\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que tienen la misma distribución que los datos originales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 16))\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[0][0], x=dataset_train.property_surface_covered)\n",
        "ax.set(title=\"distribucion de superficie cubierta\", xlabel=\"superficie cubierta\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[0][1], x=dataset_train.property_surface_total)\n",
        "ax.set(title=\"distribucion de superficie total\", xlabel=\"superficie total\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[1][0], x=dataset_imputado.property_surface_covered)\n",
        "ax.set(\n",
        "    title=\"distribucion de superficie cubierta (imputado)\", xlabel=\"superficie cubierta\"\n",
        ")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[1][1], x=dataset_imputado.property_surface_total)\n",
        "ax.set(title=\"distribucion de superficie total (imputado)\", xlabel=\"superficie total\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actualizamos los valores imputados en el nuevo dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train[columnas_a_imputar] = dataset_imputado[columnas_a_imputar].values\n",
        "\n",
        "dataset_train.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputacion de `latitud`, `longitud`, `barrio`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
