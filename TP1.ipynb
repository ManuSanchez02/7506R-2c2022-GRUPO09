{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuracion Inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuWAbUfty0_V",
        "outputId": "d1b00949-e79a-4f1c-eafa-5ceab24938ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "dataset = pd.read_csv(\"../datasets/properati_argentina_2021.csv\")\n",
        "sns.set()\n",
        "\n",
        "SEMILLA = 0\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "\n",
        "def obtener_frecuencia_relativa(series):\n",
        "    frecuencia_absoluta = series.value_counts()\n",
        "    frecuencia_relativa = frecuencia_absoluta / frecuencia_absoluta.sum()\n",
        "    return frecuencia_relativa\n",
        "\n",
        "\n",
        "def separate_date(dataset, column_name):\n",
        "    dataset[f\"{column_name}_year\"] = dataset[column_name].str[:4].astype(int)\n",
        "    dataset[f\"{column_name}_month\"] = dataset[column_name].str[5:7].astype(int)\n",
        "    dataset[f\"{column_name}_day\"] = dataset[column_name].str[8:10].astype(int)\n",
        "    dataset.drop([column_name], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8edHYLM0aEo"
      },
      "source": [
        "# 1. An√°lisis Exploratorio y Preprocesamiento de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Separacion Train-Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train, dataset_test = train_test_split(\n",
        "    dataset, test_size=TEST_SIZE, random_state=SEMILLA\n",
        ")\n",
        "\n",
        "print(\"Proporcion - Train:\", dataset_train.shape[0] / dataset.shape[0])\n",
        "print(\"Proporcion - Test:\", dataset_test.shape[0] / dataset.shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filtrado del set de Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Damos un primer vistazo al dataset, para observar las columnas y sus valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW4w811s1HSS",
        "outputId": "7f3f86de-d86c-452b-9acd-3e2cb1b2148c"
      },
      "outputs": [],
      "source": [
        "dataset_train.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos un diccionario de filtros que vamos a utilizar para filtrar nuestro dataset, y filtramos las columnas que no nos interesan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp2YYu6s0zG4",
        "outputId": "42528409-c9c4-4756-f6f6-e9f6630aecc0"
      },
      "outputs": [],
      "source": [
        "filtro_tipo_propiedad = [\"casa\", \"ph\", \"departamento\"]\n",
        "filtro_operacion = [\"venta\"]\n",
        "filtro_ubicacion = [\"capital federal\"]\n",
        "filtro_moneda = [\"usd\"]\n",
        "\n",
        "filtros = {\n",
        "    \"property_type\": filtro_tipo_propiedad,\n",
        "    \"operation\": filtro_operacion,\n",
        "    \"place_l2\": filtro_ubicacion,\n",
        "    \"property_currency\": filtro_moneda,\n",
        "}\n",
        "\n",
        "\n",
        "for columna in filtros:\n",
        "    dataset_train[columna] = dataset_train[columna].str.lower()\n",
        "\n",
        "for columna_a_filtrar, filtro in filtros.items():\n",
        "    dataset_train = dataset_train[dataset_train[columna_a_filtrar].isin(filtro)]\n",
        "\n",
        "dataset_train.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos la composicion de datos NULL en las columnas del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filas_totales = dataset_train.shape[0]\n",
        "dataset_train.isna().sum() / filas_totales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFR4QMRX6ZyH"
      },
      "source": [
        "Las columnas `place_l5` y `place_l6` contienen `NaN` en todas sus filas. Ademas, `place_4` contiene `NaN` en el 96% de sus filas. Por estas razones, eliminamos las columnas.\n",
        "\n",
        "Las columnas `id` y `property_title` no nos sirves para predecir nada, ya que son valores arbitrarios que no aportan al analisis. Por esta razon, las eliminamos tambien.\n",
        "\n",
        "Las `property_currency`, `place_l2`, `operation` solo contienen un valor posible debido al filtrado, por esto las eliminamos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "YjCKriS_6k_m",
        "outputId": "31cf7bcd-bf6a-40d5-aa46-fbc00444e2b2"
      },
      "outputs": [],
      "source": [
        "columnas_eliminar = [\n",
        "    \"property_title\",\n",
        "    \"id\",\n",
        "    \"place_l4\",\n",
        "    \"place_l5\",\n",
        "    \"place_l6\",\n",
        "    \"property_currency\",\n",
        "    \"operation\",\n",
        "    \"place_l2\",\n",
        "]\n",
        "dataset_train.drop(columnas_eliminar, axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`place_l3` no es un nombre muy significativo, lo renombramos a `barrio`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train = dataset_train.rename(columns={\"place_l3\": \"barrio\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convertimos las fechas en un mejor formato para el analisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "dataset_train[\"start_date\"] = pd.to_datetime(\n",
        "    dataset_train[\"start_date\"], errors=\"coerce\"\n",
        ")\n",
        "dataset_train[\"end_date\"] = pd.to_datetime(dataset_train[\"end_date\"], errors=\"coerce\")\n",
        "dataset_train[\"created_on\"] = pd.to_datetime(\n",
        "    dataset_train[\"created_on\"], errors=\"coerce\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpqg9SG980Ll"
      },
      "source": [
        "## Analisis Exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analisis Inicial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos la estructura general del dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Separamos el dataset en variables cualitativas, cuantitativas, y temporales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Zt4f5lXJ8vmB",
        "outputId": "3855e8f6-0fc8-4bea-bac4-ea7775921cc9"
      },
      "outputs": [],
      "source": [
        "columnas_cuantitativas = [\n",
        "    \"latitud\",\n",
        "    \"longitud\",\n",
        "    \"property_rooms\",\n",
        "    \"property_bedrooms\",\n",
        "    \"property_surface_total\",\n",
        "    \"property_surface_covered\",\n",
        "    \"property_price\",\n",
        "]\n",
        "variables_cuantitativas = dataset_train[columnas_cuantitativas]\n",
        "variables_cuantitativas.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_temporales = [\n",
        "    \"start_date\",\n",
        "    \"end_date\",\n",
        "    \"created_on\",\n",
        "]\n",
        "variables_temporales = dataset_train[columnas_temporales]\n",
        "variables_temporales.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_cualitativas = [\"barrio\", \"property_type\"]\n",
        "variables_cualitativas = dataset_train[columnas_cualitativas]\n",
        "variables_cualitativas.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables Cuantitativas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generamos estadisticas descriptivas para las columnas cuantitativas (medidas de resumen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "variables_cuantitativas.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos un mapa de correlaciones de las variables cuantitativas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "matriz_correlaciones = variables_cuantitativas.corr()\n",
        "sns.heatmap(data=matriz_correlaciones, annot=True, fmt=\".2f\", vmin=-1, vmax=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que las variables con mas relacionadas son:\n",
        " - `property_rooms` con `property_bedrooms`\n",
        " - `property_surface_covered` con `property_surface_total`.\n",
        " - `property_price` con `property_rooms` y `property_bedrooms` (con un porcentaje mucho menor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos graficos para observar estas relaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes = np.ndarray.flatten(axes)\n",
        "\n",
        "correlaciones = (\n",
        "    (\"property_rooms\", \"property_bedrooms\"),\n",
        "    (\"property_surface_covered\", \"property_surface_total\"),\n",
        "    (\"property_price\", \"property_rooms\"),\n",
        "    (\"property_price\", \"property_bedrooms\"),\n",
        ")\n",
        "for (i, correlacion) in enumerate(correlaciones):\n",
        "    sns.scatterplot(ax=axes[i], data=dataset_train, x=correlacion[0], y=correlacion[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vimos que hay cierta relacion lineal, pero es afectada por el alto numero de valores atipicos. Si los eliminamos rapidamente, el grafico cambia drasticamente. \n",
        "\n",
        "Graficamos con un _alpha_ para observar mejor la distribuci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas = (\n",
        "    \"property_surface_covered\",\n",
        "    \"property_surface_total\",\n",
        "    \"property_rooms\",\n",
        "    \"property_bedrooms\",\n",
        "    \"property_price\",\n",
        ")\n",
        "sin_atipicos = dataset_train.copy()\n",
        "for columna in columnas:\n",
        "    sin_atipicos = sin_atipicos[\n",
        "        sin_atipicos[columna] < sin_atipicos[columna].quantile(0.75) * 3.5\n",
        "    ]\n",
        "\n",
        "\n",
        "figs, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes = np.ndarray.flatten(axes)\n",
        "for (i, correlacion) in enumerate(correlaciones):\n",
        "    sns.scatterplot(ax=axes[i], data=sin_atipicos, x=correlacion[0], y=correlacion[1], alpha=0.05)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables Cualitativas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos la cantidad de valores posibles de cada variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_cualitativas.nunique()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribucion de los barrios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "NrQMh6g99Ktg",
        "outputId": "0ac2dc2c-25b4-4982-eedc-153a115cd07b"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n",
        "    nrows=1, ncols=2, figsize=(15, 5), gridspec_kw={\"width_ratios\": [3, 1]}\n",
        ")\n",
        "\n",
        "frecuencia_relativa = obtener_frecuencia_relativa(variables_cualitativas[\"barrio\"])\n",
        "ax = sns.barplot(ax=axes[0], x=frecuencia_relativa.index, y=frecuencia_relativa.values)\n",
        "ax.set(title=\"Distribucion de barrios\", xlabel=\"barios\", ylabel=\"frecuencia\")\n",
        "ax.tick_params(\"x\", labelrotation=90)\n",
        "\n",
        "frecuencia_relativa = obtener_frecuencia_relativa(\n",
        "    variables_cualitativas[\"property_type\"]\n",
        ")\n",
        "ax = sns.barplot(ax=axes[1], x=frecuencia_relativa.index, y=frecuencia_relativa.values)\n",
        "ax.set(\n",
        "    title=\"Distribucion del tipo de propiedad\",\n",
        "    xlabel=\"tipo de propiedad\",\n",
        "    ylabel=\"frecuencia\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables Temporales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribuci√≥n de las variables temporales\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
        "\n",
        "for ax in axes:\n",
        "    ax.tick_params(\"x\", labelrotation=90)\n",
        "\n",
        "sns.histplot(ax=axes[0], data=variables_temporales, x=\"start_date\", stat=\"density\").set(\n",
        "    title=\"Distribucion de fecha de inicio\"\n",
        ")\n",
        "sns.histplot(ax=axes[1], data=variables_temporales, x=\"end_date\", stat=\"density\").set(\n",
        "    title=\"Distribucion de fecha de finalizacion\"\n",
        ")\n",
        "sns.histplot(ax=axes[2], data=variables_temporales, x=\"created_on\", stat=\"density\").set(\n",
        "    title=\"Distribucion de fecha de creacion\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos eliminar `created_on`, ya que tiene distribucion practicamente identica a `start_date`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisis de Valores Atipicos (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SOLO PARA PROBAR - ACTUALIZAR CON VERDADERO ANALISIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for columna in variables_cuantitativas.columns:\n",
        "    filtro_columna = dataset_train[columna] > dataset_train[columna].quantile(0.99)\n",
        "    dataset_train[columna] = dataset_train[columna].mask(filtro_columna, np.NaN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisis de datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribucion de datos nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cantidad_de_datos_nulos_por_columna = dataset_train.isna().sum()\n",
        "frecuencia_relativa = cantidad_de_datos_nulos_por_columna / dataset_train.shape[0]\n",
        "frecuencia_relativa = frecuencia_relativa[frecuencia_relativa.values != 0]\n",
        "frecuencia_relativa = frecuencia_relativa.sort_values(ascending=False)\n",
        "\n",
        "ax = sns.barplot(x=frecuencia_relativa.index, y=frecuencia_relativa.values)\n",
        "ax.set(\n",
        "    title=\"distribucion de datos faltantes por columna\",\n",
        "    xlabel=\"columna\",\n",
        "    ylabel=\"distribucion\",\n",
        ")\n",
        "ax.tick_params(\"x\", labelrotation=90)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graficamos la distribucion de cantidad de datos faltantes por fila. \n",
        "\n",
        "Vemos que la cantidad de filas con mas de 3 datos faltantes es minima\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "distribucion_faltantes_por_fila = (\n",
        "    dataset_train.isna().sum(axis=1).value_counts() / dataset_train.shape[0]\n",
        ")\n",
        "ax = sns.barplot(\n",
        "    x=distribucion_faltantes_por_fila.index,\n",
        "    y=distribucion_faltantes_por_fila.values,\n",
        ")\n",
        "ax.set(\n",
        "    xlabel=\"Cantidad de datos faltantes por fila\",\n",
        "    ylabel=\"proporcion\",\n",
        "    title=\"proporcion de datos faltantes por fila\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputacion de datos faltante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algunas estrategias para imputar los datos faltantes:\n",
        "\n",
        "- Sustituci√≥n de Casos: Se reemplaza con valores no observados. Hay que consultar con un experto.\n",
        "- Sustituci√≥n por Media: Se reemplaza utilizando la medida calculada de los valores presentes. Sin embargo, esto trae consecuencias\n",
        "    - La varianza estimada por la nueva variable no es v√°lida ya que es atenuada por los valores repetidos\n",
        "    - Se distorsiona la distribuci√≥n\n",
        "    - Las correlaciones que se observen estaran deprimidas debido a la repetici√≥n de un solo valores constante.\n",
        "- Imputaci√≥n Cold Deck: Se pueden obtener los datos faltantes a partir de otras variables del dataset.\n",
        "- Imputacion Hot Deck: Se reemplazan los datos faltante con los valores que resultan m√°s ‚Äúsimilares‚Äù. Tenemos que definir que es ‚Äúsimilar‚Äù, para ello se puede usar la tecnica: K vecinos m√°s cercanos.\n",
        "- Imputaci√≥n por Regresi√≥n: El dato faltante es reemplaza con el valor predicho por un modelo de regresi√≥n.\n",
        "- MICE (multivariate imputation by chained equations): Trabaja bajo el supuesto de que el origen de los datos es MAR (missing at random). Es un proceso de imputaci√≥n iterativo, donde cada iteraci√≥n los valores faltantes se predicen en funci√≥n de las variables restantes. El proceso se repite hasta que se encuentre consistencia en los datos (usualmente 10 iteraciones es suficiente). La primera iteraci√≥n se realiza por uno de los m√©todos vistos anteriormente para rellenar los datos faltantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputacion `property_bedrooms`, `property_rooms`, `property_price`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Anteriormente observamos que hay una correlacion entre `property_bedrooms`, `property_rooms` y `property_price`. Podemos entrenar un modelo lineal para predecir los datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imputamos los datos utilizando un imputador iterativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_a_imputar = [\"property_bedrooms\", \"property_rooms\", \"property_price\"]\n",
        "\n",
        "modelo_lineal = LinearRegression()\n",
        "imp = IterativeImputer(\n",
        "    estimator=modelo_lineal,\n",
        "    missing_values=np.nan,\n",
        "    max_iter=20,\n",
        "    random_state=SEMILLA,\n",
        ")\n",
        "\n",
        "columnas_imputadas = imp.fit_transform(dataset_train[columnas_a_imputar])\n",
        "\n",
        "dataset_imputado = pd.DataFrame(columnas_imputadas, columns=columnas_a_imputar).astype(\n",
        "    int\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que tienen la misma distribuci√≥n que los datos originales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 16))\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[0][0], x=dataset_train.property_rooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(title=\"distribucion de cantidad de cuartos\", xlabel=\"cantidad de cuartos\")\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[0][1], x=dataset_train.property_bedrooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(title=\"distribucion de cantidad de ba√±os\", xlabel=\"cantidad de ba√±os\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[0][2], x=dataset_train.property_price)\n",
        "ax.set(title=\"distribucion de precio de propiedad\", xlabel=\"precio de propiedad\")\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[1][0], x=dataset_imputado.property_rooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(\n",
        "    title=\"distribucion de cantidad de cuartos (imputado)\", xlabel=\"cantidad de cuartos\"\n",
        ")\n",
        "\n",
        "ax = sns.histplot(\n",
        "    ax=axes[1][1], x=dataset_imputado.property_bedrooms, discrete=True, stat=\"density\"\n",
        ")\n",
        "ax.set(title=\"distribucion de cantidad de ba√±os (imputado)\", xlabel=\"cantidad de ba√±os\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[1][2], x=dataset_imputado.property_price)\n",
        "ax.set(\n",
        "    title=\"distribucion de precio de propiedad (imputado)\", xlabel=\"precio de propiedad\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actualizamos los valores imputados en el nuevo dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train[columnas_a_imputar] = dataset_imputado[columnas_a_imputar].values\n",
        "\n",
        "dataset_train.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputacion `property_surface_covered`, `property_surface_total`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tambien observamos que hay una correlacion entre `property_surface_covered`, `property_surface_total`. Podemos entrenar otro modelo lineal para predecir estos datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imputamos los datos utilizando un imputador iterativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_a_imputar = [\"property_surface_covered\", \"property_surface_total\"]\n",
        "\n",
        "modelo_lineal = LinearRegression()\n",
        "imp = IterativeImputer(\n",
        "    estimator=modelo_lineal,\n",
        "    missing_values=np.nan,\n",
        "    max_iter=20,\n",
        "    verbose=0,\n",
        "    random_state=SEMILLA,\n",
        ")\n",
        "\n",
        "columnas_imputadas = imp.fit_transform(dataset_train[columnas_a_imputar])\n",
        "\n",
        "dataset_imputado = pd.DataFrame(columnas_imputadas, columns=columnas_a_imputar).astype(\n",
        "    int\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que tienen la misma distribuci√≥n que los datos originales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 16))\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[0][0], x=dataset_train.property_surface_covered)\n",
        "ax.set(title=\"distribucion de superficie cubierta\", xlabel=\"superficie cubierta\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[0][1], x=dataset_train.property_surface_total)\n",
        "ax.set(title=\"distribucion de superficie total\", xlabel=\"superficie total\")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[1][0], x=dataset_imputado.property_surface_covered)\n",
        "ax.set(\n",
        "    title=\"distribucion de superficie cubierta (imputado)\", xlabel=\"superficie cubierta\"\n",
        ")\n",
        "\n",
        "ax = sns.kdeplot(ax=axes[1][1], x=dataset_imputado.property_surface_total)\n",
        "ax.set(title=\"distribucion de superficie total (imputado)\", xlabel=\"superficie total\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actualizamos los valores imputados en el nuevo dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_train[columnas_a_imputar] = dataset_imputado[columnas_a_imputar].values\n",
        "\n",
        "dataset_train.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputacion de `latitud`, `longitud`, `barrio`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
