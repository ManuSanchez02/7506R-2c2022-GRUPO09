{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/7506R_TP2_GRUPO09_ENTREGA_N2_(redes_neuronales).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuración inicial"
      ],
      "metadata": {
        "id": "3cOQ5uTImX6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos e instalamos las bibliotecas necesarias."
      ],
      "metadata": {
        "id": "h-pfIGiXcXXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFNpRJ4ynIL2",
        "outputId": "59b554f9-752f-4c8e-81e6-8d5dc3deada4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.8/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (21.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (1.0.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (7.9.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (2.6.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.18.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras_tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras_tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras_tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras_tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras_tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (2.10)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.50.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (2.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.38.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (3.4.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (3.19.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras_tuner) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qOP4jk4AkKFo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense  \n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    recall_score, \n",
        "    accuracy_score, \n",
        "    f1_score,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        ")\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funciones útiles"
      ],
      "metadata": {
        "id": "UUz0MBqpkAws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graficar_matriz_de_confusion(y_test, y_pred, labels):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fig = plt.figure(figsize = (12, 10))\n",
        "    sns.heatmap(\n",
        "        cm, annot=True, xticklabels=labels, yticklabels=labels, cmap=\"GnBu\", fmt=\"g\"\n",
        "    )\n",
        "    plt.title(\"Matriz de confusión\")\n",
        "    plt.xlabel(\"Predichos\")\n",
        "    plt.ylabel(\"Verdaderos\")\n",
        "    plt.show()\n",
        "\n",
        "def imprimir_metricas_de_clasificacion(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "    print(\"\\nMétricas de clasificación\\n\")\n",
        "    print(\"Accuracy: \" + str(accuracy))\n",
        "    print(\"Recall: \" + str(recall))\n",
        "    print(\"F1 score: \" + str(f1))\n",
        "\n",
        "def imprimir_metricas_de_regresion(target_test, precios_predichos):\n",
        "    # Error cuadrático medio\n",
        "    mse = mean_squared_error(\n",
        "        y_true=target_test, y_pred=precios_predichos, squared=True\n",
        "    )\n",
        "\n",
        "    # Raíz del error cuadrático medio\n",
        "    rmse = mean_squared_error(\n",
        "        y_true=target_test, y_pred=precios_predichos, squared=False\n",
        "    )\n",
        "\n",
        "    # Score R2\n",
        "    r2 = r2_score(target_test, precios_predichos)\n",
        "\n",
        "    print(\"\\nMétricas de regresión\\n\")\n",
        "    print(f\"El error (mse) de test es: {mse}\")\n",
        "    print(f\"El error (rmse) de test es: {rmse}\")\n",
        "    print(f\"El score R2 es: {r2}\")"
      ],
      "metadata": {
        "id": "PkJTaUgFkAWU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos los datasets que se utilizarán para trabajar."
      ],
      "metadata": {
        "id": "rOBCASz1caTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train_clasificacion = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/clasificacion_train_feature.csv?raw=True\")\n",
        "dataset_test_clasificacion = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/clasificacion_test_feature.csv?raw=True\")\n",
        "\n",
        "dataset_train_regresion = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/regresion_train_feature.csv?raw=True\")\n",
        "dataset_test_regresion = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/regresion_test_feature.csv?raw=True\")"
      ],
      "metadata": {
        "id": "XebCvscRmwLv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_clasificacion_categorico = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/clasificacion_train_target.csv?raw=True\")\n",
        "y_test_clasificacion_categorico = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/clasificacion_test_target.csv?raw=True\")\n",
        "\n",
        "y_train_regresion = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/regresion_train_target.csv?raw=True\")\n",
        "y_test_regresion = pd.read_csv(\"https://github.com/ManuSanchez02/7506R-2c2022-GRUPO09/blob/main/tp2/datasets/regresion_test_target.csv?raw=True\")\n"
      ],
      "metadata": {
        "id": "a2-liQcIp9oq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preparar_dataset(dataset):\n",
        "  dataset.drop(\"Unnamed: 0\", axis = 1, inplace=True)\n",
        "  dataset.drop(\"id\", axis = 1, inplace=True)\n",
        "  return dataset\n",
        "\n",
        "def preparar_target(target):\n",
        "  target.drop(\"Unnamed: 0\", axis = 1, inplace=True)\n",
        "  return target\n",
        "\n",
        "dataset_train_clasificacion = preparar_dataset(dataset_train_clasificacion)\n",
        "dataset_test_clasificacion = preparar_dataset(dataset_test_clasificacion)\n",
        "dataset_train_regresion = preparar_dataset(dataset_train_regresion)\n",
        "dataset_test_regresion = preparar_dataset(dataset_test_regresion)\n",
        "\n",
        "y_train_clasificacion_categorico = preparar_target(y_train_clasificacion_categorico)\n",
        "y_test_clasificacion_categorico = preparar_target(y_test_clasificacion_categorico)\n",
        "y_train_regresion = preparar_target(y_train_regresion)\n",
        "y_test_regresion = preparar_target(y_test_regresion)"
      ],
      "metadata": {
        "id": "3_YKbPomhkHg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos las categorías del target de clasificación en categorías numéricas para poder utilizarlas en la red neuronal."
      ],
      "metadata": {
        "id": "rUNdvWgXkVcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "y_train_clasificacion = le.fit_transform(y_train_clasificacion_categorico)\n",
        "y_test_clasificacion = le.transform(y_test_clasificacion_categorico)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYt3ogqvznAs",
        "outputId": "08aeea98-58ae-4ee2-ad07-22ef8f646e96"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes neuronales"
      ],
      "metadata": {
        "id": "mm8tqJTjri0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escalamos los datos para que performe mejor."
      ],
      "metadata": {
        "id": "PQcM4a43uyLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_clasificacion = StandardScaler()\n",
        "scaler_clasificacion.fit(dataset_train_clasificacion)\n",
        "\n",
        "scaler_regresion = StandardScaler()\n",
        "scaler_regresion.fit(dataset_train_regresion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKBhO22CuzDl",
        "outputId": "d3e3b1e1-1d0b-4f5e-b257-3c0adab50506"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clasificacion = scaler_clasificacion.transform(dataset_train_clasificacion)\n",
        "x_test_clasificacion = scaler_clasificacion.transform(dataset_test_clasificacion)\n",
        "\n",
        "x_train_regresion = scaler_regresion.transform(dataset_train_regresion)\n",
        "x_test_regresion = scaler_regresion.transform(dataset_test_regresion)\n"
      ],
      "metadata": {
        "id": "KqEfDf81u5rP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificación"
      ],
      "metadata": {
        "id": "ADBWjJkzrcNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos las salidas del modelo."
      ],
      "metadata": {
        "id": "eiuTK7_kIyxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = {\n",
        "    \"bajo\": 0,\n",
        "    \"medio\": 1,\n",
        "    \"alto\": 2,\n",
        "}"
      ],
      "metadata": {
        "id": "dPlrlxpb08YB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el modelo secuencial de Keras."
      ],
      "metadata": {
        "id": "uqhEx5Retbao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Dense(\n",
        "      hp.Int('units', min_value=32, max_value=512, step=16),\n",
        "      activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"])))\n",
        "  model.add(keras.layers.Dense(10, activation=\"tanh\"))\n",
        "  model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
        "  learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-1, sampling=\"log\")\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), \n",
        "                optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "QEfU9q3Q2LYT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos un Randomized Search para buscar los mejores hiperparámetros."
      ],
      "metadata": {
        "id": "-SZ09lL_MFzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='loss',\n",
        "    max_trials=10,\n",
        "    project_name=\"Clasificacion\",\n",
        "    overwrite=True)"
      ],
      "metadata": {
        "id": "QnCvyfqn2L0J"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
        "tuner.search(x_train_clasificacion, y_train_clasificacion, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
        "best_model = tuner.get_best_models()[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhKRaNrWjxCT",
        "outputId": "a8510c89-3686-477a-eb4c-eef06f6f65df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 31s]\n",
            "loss: 0.8263664841651917\n",
            "\n",
            "Best loss So Far: 0.8020757436752319\n",
            "Total elapsed time: 00h 06m 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos los resultados del mejor modelo obtenido."
      ],
      "metadata": {
        "id": "JI_mVJiVMK8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "best_hps.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys7BdJmzA9dM",
        "outputId": "9ef38e7a-2f47-441a-b5aa-a74c2eb774f8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 496, 'activation': 'tanh', 'lr': 0.00046002804367732453}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = build_model(best_hps)\n",
        "best_model.fit(x=x_train_clasificacion, y=y_train_clasificacion, epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVj_MMv7N6Cx",
        "outputId": "906a3e01-96d1-484a-b73b-c2b41fb884f9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2163/2163 [==============================] - 7s 2ms/step - loss: 0.8633 - accuracy: 0.5845\n",
            "Epoch 2/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8333 - accuracy: 0.5998\n",
            "Epoch 3/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8243 - accuracy: 0.6036\n",
            "Epoch 4/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8171 - accuracy: 0.6073\n",
            "Epoch 5/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8122 - accuracy: 0.6077\n",
            "Epoch 6/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8082 - accuracy: 0.6105\n",
            "Epoch 7/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8054 - accuracy: 0.6107\n",
            "Epoch 8/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8036 - accuracy: 0.6121\n",
            "Epoch 9/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.8013 - accuracy: 0.6113\n",
            "Epoch 10/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7998 - accuracy: 0.6128\n",
            "Epoch 11/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7984 - accuracy: 0.6146\n",
            "Epoch 12/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7967 - accuracy: 0.6147\n",
            "Epoch 13/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7955 - accuracy: 0.6150\n",
            "Epoch 14/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7937 - accuracy: 0.6149\n",
            "Epoch 15/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7923 - accuracy: 0.6155\n",
            "Epoch 16/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7918 - accuracy: 0.6171\n",
            "Epoch 17/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7896 - accuracy: 0.6173\n",
            "Epoch 18/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7893 - accuracy: 0.6190\n",
            "Epoch 19/500\n",
            "2163/2163 [==============================] - 10s 5ms/step - loss: 0.7878 - accuracy: 0.6202\n",
            "Epoch 20/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7865 - accuracy: 0.6195\n",
            "Epoch 21/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7854 - accuracy: 0.6196\n",
            "Epoch 22/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7849 - accuracy: 0.6200\n",
            "Epoch 23/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7837 - accuracy: 0.6215\n",
            "Epoch 24/500\n",
            "2163/2163 [==============================] - 12s 5ms/step - loss: 0.7832 - accuracy: 0.6212\n",
            "Epoch 25/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7820 - accuracy: 0.6230\n",
            "Epoch 26/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7809 - accuracy: 0.6246\n",
            "Epoch 27/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7803 - accuracy: 0.6231\n",
            "Epoch 28/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7802 - accuracy: 0.6230\n",
            "Epoch 29/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7782 - accuracy: 0.6246\n",
            "Epoch 30/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7780 - accuracy: 0.6247\n",
            "Epoch 31/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7775 - accuracy: 0.6253\n",
            "Epoch 32/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7765 - accuracy: 0.6258\n",
            "Epoch 33/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7756 - accuracy: 0.6259\n",
            "Epoch 34/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7749 - accuracy: 0.6263\n",
            "Epoch 35/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7744 - accuracy: 0.6275\n",
            "Epoch 36/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7734 - accuracy: 0.6269\n",
            "Epoch 37/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7729 - accuracy: 0.6282\n",
            "Epoch 38/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7723 - accuracy: 0.6283\n",
            "Epoch 39/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7716 - accuracy: 0.6277\n",
            "Epoch 40/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7707 - accuracy: 0.6295\n",
            "Epoch 41/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7704 - accuracy: 0.6280\n",
            "Epoch 42/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7696 - accuracy: 0.6294\n",
            "Epoch 43/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7682 - accuracy: 0.6301\n",
            "Epoch 44/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7683 - accuracy: 0.6307\n",
            "Epoch 45/500\n",
            "2163/2163 [==============================] - 10s 4ms/step - loss: 0.7672 - accuracy: 0.6308\n",
            "Epoch 46/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7669 - accuracy: 0.6308\n",
            "Epoch 47/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7658 - accuracy: 0.6317\n",
            "Epoch 48/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7655 - accuracy: 0.6322\n",
            "Epoch 49/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7651 - accuracy: 0.6328\n",
            "Epoch 50/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7639 - accuracy: 0.6325\n",
            "Epoch 51/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7632 - accuracy: 0.6325\n",
            "Epoch 52/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7621 - accuracy: 0.6344\n",
            "Epoch 53/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7626 - accuracy: 0.6339\n",
            "Epoch 54/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7617 - accuracy: 0.6338\n",
            "Epoch 55/500\n",
            "2163/2163 [==============================] - 12s 5ms/step - loss: 0.7611 - accuracy: 0.6343\n",
            "Epoch 56/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7609 - accuracy: 0.6346\n",
            "Epoch 57/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7600 - accuracy: 0.6344\n",
            "Epoch 58/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7591 - accuracy: 0.6349\n",
            "Epoch 59/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7588 - accuracy: 0.6350\n",
            "Epoch 60/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7578 - accuracy: 0.6364\n",
            "Epoch 61/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7578 - accuracy: 0.6362\n",
            "Epoch 62/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7576 - accuracy: 0.6351\n",
            "Epoch 63/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7560 - accuracy: 0.6366\n",
            "Epoch 64/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7560 - accuracy: 0.6376\n",
            "Epoch 65/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7556 - accuracy: 0.6375\n",
            "Epoch 66/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7552 - accuracy: 0.6396\n",
            "Epoch 67/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7544 - accuracy: 0.6379\n",
            "Epoch 68/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7539 - accuracy: 0.6395\n",
            "Epoch 69/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7534 - accuracy: 0.6382\n",
            "Epoch 70/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7527 - accuracy: 0.6391\n",
            "Epoch 71/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7525 - accuracy: 0.6394\n",
            "Epoch 72/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7520 - accuracy: 0.6394\n",
            "Epoch 73/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7517 - accuracy: 0.6392\n",
            "Epoch 74/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7511 - accuracy: 0.6397\n",
            "Epoch 75/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7512 - accuracy: 0.6401\n",
            "Epoch 76/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7502 - accuracy: 0.6404\n",
            "Epoch 77/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7499 - accuracy: 0.6404\n",
            "Epoch 78/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7496 - accuracy: 0.6406\n",
            "Epoch 79/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7487 - accuracy: 0.6418\n",
            "Epoch 80/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7485 - accuracy: 0.6434\n",
            "Epoch 81/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7480 - accuracy: 0.6423\n",
            "Epoch 82/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7471 - accuracy: 0.6425\n",
            "Epoch 83/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7468 - accuracy: 0.6428\n",
            "Epoch 84/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7466 - accuracy: 0.6422\n",
            "Epoch 85/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7457 - accuracy: 0.6433\n",
            "Epoch 86/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7457 - accuracy: 0.6434\n",
            "Epoch 87/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7451 - accuracy: 0.6429\n",
            "Epoch 88/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7442 - accuracy: 0.6447\n",
            "Epoch 89/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7441 - accuracy: 0.6437\n",
            "Epoch 90/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7439 - accuracy: 0.6442\n",
            "Epoch 91/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7438 - accuracy: 0.6440\n",
            "Epoch 92/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7432 - accuracy: 0.6435\n",
            "Epoch 93/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7426 - accuracy: 0.6452\n",
            "Epoch 94/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7421 - accuracy: 0.6458\n",
            "Epoch 95/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7419 - accuracy: 0.6445\n",
            "Epoch 96/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7418 - accuracy: 0.6455\n",
            "Epoch 97/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7412 - accuracy: 0.6460\n",
            "Epoch 98/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7407 - accuracy: 0.6467\n",
            "Epoch 99/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7404 - accuracy: 0.6457\n",
            "Epoch 100/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7397 - accuracy: 0.6462\n",
            "Epoch 101/500\n",
            "2163/2163 [==============================] - 15s 7ms/step - loss: 0.7396 - accuracy: 0.6466\n",
            "Epoch 102/500\n",
            "2163/2163 [==============================] - 10s 5ms/step - loss: 0.7391 - accuracy: 0.6462\n",
            "Epoch 103/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7388 - accuracy: 0.6473\n",
            "Epoch 104/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7379 - accuracy: 0.6481\n",
            "Epoch 105/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7380 - accuracy: 0.6471\n",
            "Epoch 106/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7373 - accuracy: 0.6487\n",
            "Epoch 107/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7369 - accuracy: 0.6481\n",
            "Epoch 108/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7366 - accuracy: 0.6495\n",
            "Epoch 109/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7366 - accuracy: 0.6490\n",
            "Epoch 110/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7361 - accuracy: 0.6483\n",
            "Epoch 111/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7352 - accuracy: 0.6498\n",
            "Epoch 112/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7345 - accuracy: 0.6491\n",
            "Epoch 113/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7345 - accuracy: 0.6499\n",
            "Epoch 114/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7338 - accuracy: 0.6493\n",
            "Epoch 115/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7339 - accuracy: 0.6500\n",
            "Epoch 116/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7336 - accuracy: 0.6506\n",
            "Epoch 117/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7331 - accuracy: 0.6508\n",
            "Epoch 118/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7328 - accuracy: 0.6495\n",
            "Epoch 119/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7330 - accuracy: 0.6502\n",
            "Epoch 120/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7314 - accuracy: 0.6518\n",
            "Epoch 121/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7321 - accuracy: 0.6507\n",
            "Epoch 122/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7313 - accuracy: 0.6524\n",
            "Epoch 123/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7313 - accuracy: 0.6528\n",
            "Epoch 124/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7307 - accuracy: 0.6524\n",
            "Epoch 125/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7298 - accuracy: 0.6523\n",
            "Epoch 126/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7295 - accuracy: 0.6538\n",
            "Epoch 127/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7295 - accuracy: 0.6521\n",
            "Epoch 128/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7291 - accuracy: 0.6534\n",
            "Epoch 129/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7284 - accuracy: 0.6527\n",
            "Epoch 130/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7286 - accuracy: 0.6540\n",
            "Epoch 131/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7284 - accuracy: 0.6531\n",
            "Epoch 132/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7278 - accuracy: 0.6545\n",
            "Epoch 133/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7268 - accuracy: 0.6557\n",
            "Epoch 134/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7269 - accuracy: 0.6547\n",
            "Epoch 135/500\n",
            "2163/2163 [==============================] - 10s 5ms/step - loss: 0.7268 - accuracy: 0.6556\n",
            "Epoch 136/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7264 - accuracy: 0.6539\n",
            "Epoch 137/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7263 - accuracy: 0.6549\n",
            "Epoch 138/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7256 - accuracy: 0.6562\n",
            "Epoch 139/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7260 - accuracy: 0.6548\n",
            "Epoch 140/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7255 - accuracy: 0.6550\n",
            "Epoch 141/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7247 - accuracy: 0.6556\n",
            "Epoch 142/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7247 - accuracy: 0.6552\n",
            "Epoch 143/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7241 - accuracy: 0.6568\n",
            "Epoch 144/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7239 - accuracy: 0.6553\n",
            "Epoch 145/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7240 - accuracy: 0.6568\n",
            "Epoch 146/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7232 - accuracy: 0.6572\n",
            "Epoch 147/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7228 - accuracy: 0.6561\n",
            "Epoch 148/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7227 - accuracy: 0.6563\n",
            "Epoch 149/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7221 - accuracy: 0.6582\n",
            "Epoch 150/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7221 - accuracy: 0.6578\n",
            "Epoch 151/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7218 - accuracy: 0.6572\n",
            "Epoch 152/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7212 - accuracy: 0.6587\n",
            "Epoch 153/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7210 - accuracy: 0.6567\n",
            "Epoch 154/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7207 - accuracy: 0.6581\n",
            "Epoch 155/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7207 - accuracy: 0.6574\n",
            "Epoch 156/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7198 - accuracy: 0.6590\n",
            "Epoch 157/500\n",
            "2163/2163 [==============================] - 10s 5ms/step - loss: 0.7200 - accuracy: 0.6583\n",
            "Epoch 158/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7195 - accuracy: 0.6584\n",
            "Epoch 159/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7194 - accuracy: 0.6585\n",
            "Epoch 160/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7190 - accuracy: 0.6590\n",
            "Epoch 161/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7190 - accuracy: 0.6588\n",
            "Epoch 162/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7183 - accuracy: 0.6595\n",
            "Epoch 163/500\n",
            "2163/2163 [==============================] - 11s 5ms/step - loss: 0.7181 - accuracy: 0.6592\n",
            "Epoch 164/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7179 - accuracy: 0.6590\n",
            "Epoch 165/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7174 - accuracy: 0.6589\n",
            "Epoch 166/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7172 - accuracy: 0.6618\n",
            "Epoch 167/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7167 - accuracy: 0.6596\n",
            "Epoch 168/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7162 - accuracy: 0.6614\n",
            "Epoch 169/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7169 - accuracy: 0.6605\n",
            "Epoch 170/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7162 - accuracy: 0.6604\n",
            "Epoch 171/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7159 - accuracy: 0.6615\n",
            "Epoch 172/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7157 - accuracy: 0.6609\n",
            "Epoch 173/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7154 - accuracy: 0.6613\n",
            "Epoch 174/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7146 - accuracy: 0.6615\n",
            "Epoch 175/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7148 - accuracy: 0.6621\n",
            "Epoch 176/500\n",
            "2163/2163 [==============================] - 14s 6ms/step - loss: 0.7149 - accuracy: 0.6619\n",
            "Epoch 177/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7145 - accuracy: 0.6617\n",
            "Epoch 178/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7139 - accuracy: 0.6613\n",
            "Epoch 179/500\n",
            "2163/2163 [==============================] - 11s 5ms/step - loss: 0.7143 - accuracy: 0.6618\n",
            "Epoch 180/500\n",
            "2163/2163 [==============================] - 10s 5ms/step - loss: 0.7133 - accuracy: 0.6623\n",
            "Epoch 181/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7130 - accuracy: 0.6626\n",
            "Epoch 182/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7133 - accuracy: 0.6629\n",
            "Epoch 183/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7132 - accuracy: 0.6618\n",
            "Epoch 184/500\n",
            "2163/2163 [==============================] - 8s 3ms/step - loss: 0.7125 - accuracy: 0.6623\n",
            "Epoch 185/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 0.7117 - accuracy: 0.6624\n",
            "Epoch 186/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7116 - accuracy: 0.6631\n",
            "Epoch 187/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7116 - accuracy: 0.6632\n",
            "Epoch 188/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7110 - accuracy: 0.6625\n",
            "Epoch 189/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7111 - accuracy: 0.6633\n",
            "Epoch 190/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7106 - accuracy: 0.6652\n",
            "Epoch 191/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7106 - accuracy: 0.6637\n",
            "Epoch 192/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7110 - accuracy: 0.6645\n",
            "Epoch 193/500\n",
            "2163/2163 [==============================] - 9s 4ms/step - loss: 0.7103 - accuracy: 0.6636\n",
            "Epoch 194/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7104 - accuracy: 0.6638\n",
            "Epoch 195/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7096 - accuracy: 0.6637\n",
            "Epoch 196/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7093 - accuracy: 0.6648\n",
            "Epoch 197/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7090 - accuracy: 0.6653\n",
            "Epoch 198/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7088 - accuracy: 0.6651\n",
            "Epoch 199/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7083 - accuracy: 0.6641\n",
            "Epoch 200/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7092 - accuracy: 0.6642\n",
            "Epoch 201/500\n",
            "2163/2163 [==============================] - 10s 4ms/step - loss: 0.7083 - accuracy: 0.6647\n",
            "Epoch 202/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7078 - accuracy: 0.6642\n",
            "Epoch 203/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7080 - accuracy: 0.6660\n",
            "Epoch 204/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7070 - accuracy: 0.6650\n",
            "Epoch 205/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7079 - accuracy: 0.6656\n",
            "Epoch 206/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7067 - accuracy: 0.6648\n",
            "Epoch 207/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7068 - accuracy: 0.6662\n",
            "Epoch 208/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7066 - accuracy: 0.6658\n",
            "Epoch 209/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7064 - accuracy: 0.6659\n",
            "Epoch 210/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7061 - accuracy: 0.6674\n",
            "Epoch 211/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7058 - accuracy: 0.6659\n",
            "Epoch 212/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7055 - accuracy: 0.6674\n",
            "Epoch 213/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7059 - accuracy: 0.6661\n",
            "Epoch 214/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7053 - accuracy: 0.6663\n",
            "Epoch 215/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7051 - accuracy: 0.6656\n",
            "Epoch 216/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7045 - accuracy: 0.6665\n",
            "Epoch 217/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7045 - accuracy: 0.6673\n",
            "Epoch 218/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7041 - accuracy: 0.6669\n",
            "Epoch 219/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7042 - accuracy: 0.6678\n",
            "Epoch 220/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7035 - accuracy: 0.6672\n",
            "Epoch 221/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7037 - accuracy: 0.6690\n",
            "Epoch 222/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7039 - accuracy: 0.6665\n",
            "Epoch 223/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7034 - accuracy: 0.6678\n",
            "Epoch 224/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7032 - accuracy: 0.6679\n",
            "Epoch 225/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7026 - accuracy: 0.6680\n",
            "Epoch 226/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7022 - accuracy: 0.6694\n",
            "Epoch 227/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7022 - accuracy: 0.6689\n",
            "Epoch 228/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7021 - accuracy: 0.6689\n",
            "Epoch 229/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7018 - accuracy: 0.6690\n",
            "Epoch 230/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7023 - accuracy: 0.6676\n",
            "Epoch 231/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.7018 - accuracy: 0.6690\n",
            "Epoch 232/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7017 - accuracy: 0.6685\n",
            "Epoch 233/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7010 - accuracy: 0.6699\n",
            "Epoch 234/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.7013 - accuracy: 0.6702\n",
            "Epoch 235/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.7009 - accuracy: 0.6686\n",
            "Epoch 236/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7009 - accuracy: 0.6703\n",
            "Epoch 237/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7002 - accuracy: 0.6709\n",
            "Epoch 238/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.7002 - accuracy: 0.6696\n",
            "Epoch 239/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6995 - accuracy: 0.6699\n",
            "Epoch 240/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6999 - accuracy: 0.6714\n",
            "Epoch 241/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6996 - accuracy: 0.6702\n",
            "Epoch 242/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6992 - accuracy: 0.6687\n",
            "Epoch 243/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6987 - accuracy: 0.6704\n",
            "Epoch 244/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6987 - accuracy: 0.6710\n",
            "Epoch 245/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6987 - accuracy: 0.6727\n",
            "Epoch 246/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6984 - accuracy: 0.6704\n",
            "Epoch 247/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6975 - accuracy: 0.6696\n",
            "Epoch 248/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6983 - accuracy: 0.6708\n",
            "Epoch 249/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6981 - accuracy: 0.6694\n",
            "Epoch 250/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6975 - accuracy: 0.6701\n",
            "Epoch 251/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6972 - accuracy: 0.6716\n",
            "Epoch 252/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6968 - accuracy: 0.6701\n",
            "Epoch 253/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6966 - accuracy: 0.6720\n",
            "Epoch 254/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6966 - accuracy: 0.6713\n",
            "Epoch 255/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6963 - accuracy: 0.6717\n",
            "Epoch 256/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6965 - accuracy: 0.6720\n",
            "Epoch 257/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6965 - accuracy: 0.6723\n",
            "Epoch 258/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6958 - accuracy: 0.6715\n",
            "Epoch 259/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6957 - accuracy: 0.6721\n",
            "Epoch 260/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6953 - accuracy: 0.6721\n",
            "Epoch 261/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6948 - accuracy: 0.6717\n",
            "Epoch 262/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6955 - accuracy: 0.6709\n",
            "Epoch 263/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6949 - accuracy: 0.6721\n",
            "Epoch 264/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6946 - accuracy: 0.6722\n",
            "Epoch 265/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6941 - accuracy: 0.6726\n",
            "Epoch 266/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6952 - accuracy: 0.6718\n",
            "Epoch 267/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6942 - accuracy: 0.6714\n",
            "Epoch 268/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6939 - accuracy: 0.6738\n",
            "Epoch 269/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6941 - accuracy: 0.6729\n",
            "Epoch 270/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6929 - accuracy: 0.6732\n",
            "Epoch 271/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6935 - accuracy: 0.6725\n",
            "Epoch 272/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6935 - accuracy: 0.6726\n",
            "Epoch 273/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6934 - accuracy: 0.6737\n",
            "Epoch 274/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6929 - accuracy: 0.6731\n",
            "Epoch 275/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6935 - accuracy: 0.6720\n",
            "Epoch 276/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6933 - accuracy: 0.6746\n",
            "Epoch 277/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6925 - accuracy: 0.6734\n",
            "Epoch 278/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6925 - accuracy: 0.6727\n",
            "Epoch 279/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6920 - accuracy: 0.6735\n",
            "Epoch 280/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6919 - accuracy: 0.6739\n",
            "Epoch 281/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6921 - accuracy: 0.6742\n",
            "Epoch 282/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6912 - accuracy: 0.6749\n",
            "Epoch 283/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6913 - accuracy: 0.6745\n",
            "Epoch 284/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6912 - accuracy: 0.6746\n",
            "Epoch 285/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6909 - accuracy: 0.6741\n",
            "Epoch 286/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.6912 - accuracy: 0.6745\n",
            "Epoch 287/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6906 - accuracy: 0.6759\n",
            "Epoch 288/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6912 - accuracy: 0.6751\n",
            "Epoch 289/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6904 - accuracy: 0.6753\n",
            "Epoch 290/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6908 - accuracy: 0.6752\n",
            "Epoch 291/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6897 - accuracy: 0.6773\n",
            "Epoch 292/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6901 - accuracy: 0.6756\n",
            "Epoch 293/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6900 - accuracy: 0.6750\n",
            "Epoch 294/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6901 - accuracy: 0.6745\n",
            "Epoch 295/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6896 - accuracy: 0.6754\n",
            "Epoch 296/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6892 - accuracy: 0.6749\n",
            "Epoch 297/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6896 - accuracy: 0.6752\n",
            "Epoch 298/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6890 - accuracy: 0.6763\n",
            "Epoch 299/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6894 - accuracy: 0.6761\n",
            "Epoch 300/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6883 - accuracy: 0.6756\n",
            "Epoch 301/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6888 - accuracy: 0.6750\n",
            "Epoch 302/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6885 - accuracy: 0.6765\n",
            "Epoch 303/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6884 - accuracy: 0.6765\n",
            "Epoch 304/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6884 - accuracy: 0.6774\n",
            "Epoch 305/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6885 - accuracy: 0.6748\n",
            "Epoch 306/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6878 - accuracy: 0.6760\n",
            "Epoch 307/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6877 - accuracy: 0.6764\n",
            "Epoch 308/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6879 - accuracy: 0.6751\n",
            "Epoch 309/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6878 - accuracy: 0.6758\n",
            "Epoch 310/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6877 - accuracy: 0.6756\n",
            "Epoch 311/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6872 - accuracy: 0.6763\n",
            "Epoch 312/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6867 - accuracy: 0.6769\n",
            "Epoch 313/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6867 - accuracy: 0.6774\n",
            "Epoch 314/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6868 - accuracy: 0.6758\n",
            "Epoch 315/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6865 - accuracy: 0.6760\n",
            "Epoch 316/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6865 - accuracy: 0.6773\n",
            "Epoch 317/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6857 - accuracy: 0.6791\n",
            "Epoch 318/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6858 - accuracy: 0.6767\n",
            "Epoch 319/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6859 - accuracy: 0.6764\n",
            "Epoch 320/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6862 - accuracy: 0.6767\n",
            "Epoch 321/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6849 - accuracy: 0.6777\n",
            "Epoch 322/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6857 - accuracy: 0.6772\n",
            "Epoch 323/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6849 - accuracy: 0.6791\n",
            "Epoch 324/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6854 - accuracy: 0.6776\n",
            "Epoch 325/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6846 - accuracy: 0.6770\n",
            "Epoch 326/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6847 - accuracy: 0.6779\n",
            "Epoch 327/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6850 - accuracy: 0.6784\n",
            "Epoch 328/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6838 - accuracy: 0.6775\n",
            "Epoch 329/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6842 - accuracy: 0.6776\n",
            "Epoch 330/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6847 - accuracy: 0.6769\n",
            "Epoch 331/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6843 - accuracy: 0.6783\n",
            "Epoch 332/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6838 - accuracy: 0.6777\n",
            "Epoch 333/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6841 - accuracy: 0.6768\n",
            "Epoch 334/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6833 - accuracy: 0.6781\n",
            "Epoch 335/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6832 - accuracy: 0.6793\n",
            "Epoch 336/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6831 - accuracy: 0.6790\n",
            "Epoch 337/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6834 - accuracy: 0.6770\n",
            "Epoch 338/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6832 - accuracy: 0.6793\n",
            "Epoch 339/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6829 - accuracy: 0.6781\n",
            "Epoch 340/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6828 - accuracy: 0.6788\n",
            "Epoch 341/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6824 - accuracy: 0.6796\n",
            "Epoch 342/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6824 - accuracy: 0.6787\n",
            "Epoch 343/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6823 - accuracy: 0.6780\n",
            "Epoch 344/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6823 - accuracy: 0.6793\n",
            "Epoch 345/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6822 - accuracy: 0.6781\n",
            "Epoch 346/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6818 - accuracy: 0.6797\n",
            "Epoch 347/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6819 - accuracy: 0.6804\n",
            "Epoch 348/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6818 - accuracy: 0.6790\n",
            "Epoch 349/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6815 - accuracy: 0.6794\n",
            "Epoch 350/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6815 - accuracy: 0.6791\n",
            "Epoch 351/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6816 - accuracy: 0.6791\n",
            "Epoch 352/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6812 - accuracy: 0.6791\n",
            "Epoch 353/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6811 - accuracy: 0.6801\n",
            "Epoch 354/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6804 - accuracy: 0.6813\n",
            "Epoch 355/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6810 - accuracy: 0.6796\n",
            "Epoch 356/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6805 - accuracy: 0.6801\n",
            "Epoch 357/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6806 - accuracy: 0.6789\n",
            "Epoch 358/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6800 - accuracy: 0.6807\n",
            "Epoch 359/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6795 - accuracy: 0.6822\n",
            "Epoch 360/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6798 - accuracy: 0.6804\n",
            "Epoch 361/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6794 - accuracy: 0.6795\n",
            "Epoch 362/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6799 - accuracy: 0.6819\n",
            "Epoch 363/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6791 - accuracy: 0.6802\n",
            "Epoch 364/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6794 - accuracy: 0.6809\n",
            "Epoch 365/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6790 - accuracy: 0.6801\n",
            "Epoch 366/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6791 - accuracy: 0.6808\n",
            "Epoch 367/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6788 - accuracy: 0.6809\n",
            "Epoch 368/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6790 - accuracy: 0.6809\n",
            "Epoch 369/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6787 - accuracy: 0.6813\n",
            "Epoch 370/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6785 - accuracy: 0.6804\n",
            "Epoch 371/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6785 - accuracy: 0.6828\n",
            "Epoch 372/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6784 - accuracy: 0.6819\n",
            "Epoch 373/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6779 - accuracy: 0.6818\n",
            "Epoch 374/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6779 - accuracy: 0.6792\n",
            "Epoch 375/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6786 - accuracy: 0.6813\n",
            "Epoch 376/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6773 - accuracy: 0.6827\n",
            "Epoch 377/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6781 - accuracy: 0.6803\n",
            "Epoch 378/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6772 - accuracy: 0.6824\n",
            "Epoch 379/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6775 - accuracy: 0.6816\n",
            "Epoch 380/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6776 - accuracy: 0.6816\n",
            "Epoch 381/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6767 - accuracy: 0.6816\n",
            "Epoch 382/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6774 - accuracy: 0.6821\n",
            "Epoch 383/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6767 - accuracy: 0.6818\n",
            "Epoch 384/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6765 - accuracy: 0.6833\n",
            "Epoch 385/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6764 - accuracy: 0.6825\n",
            "Epoch 386/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6768 - accuracy: 0.6822\n",
            "Epoch 387/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6758 - accuracy: 0.6829\n",
            "Epoch 388/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6767 - accuracy: 0.6834\n",
            "Epoch 389/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6770 - accuracy: 0.6816\n",
            "Epoch 390/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6758 - accuracy: 0.6819\n",
            "Epoch 391/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6763 - accuracy: 0.6830\n",
            "Epoch 392/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6759 - accuracy: 0.6827\n",
            "Epoch 393/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6756 - accuracy: 0.6832\n",
            "Epoch 394/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6759 - accuracy: 0.6827\n",
            "Epoch 395/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6749 - accuracy: 0.6827\n",
            "Epoch 396/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6758 - accuracy: 0.6826\n",
            "Epoch 397/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6755 - accuracy: 0.6821\n",
            "Epoch 398/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6750 - accuracy: 0.6832\n",
            "Epoch 399/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6750 - accuracy: 0.6839\n",
            "Epoch 400/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6745 - accuracy: 0.6839\n",
            "Epoch 401/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6752 - accuracy: 0.6830\n",
            "Epoch 402/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6743 - accuracy: 0.6841\n",
            "Epoch 403/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6743 - accuracy: 0.6830\n",
            "Epoch 404/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6745 - accuracy: 0.6836\n",
            "Epoch 405/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6741 - accuracy: 0.6839\n",
            "Epoch 406/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6740 - accuracy: 0.6834\n",
            "Epoch 407/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6742 - accuracy: 0.6832\n",
            "Epoch 408/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6740 - accuracy: 0.6833\n",
            "Epoch 409/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6736 - accuracy: 0.6857\n",
            "Epoch 410/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6737 - accuracy: 0.6838\n",
            "Epoch 411/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6734 - accuracy: 0.6841\n",
            "Epoch 412/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6733 - accuracy: 0.6833\n",
            "Epoch 413/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6735 - accuracy: 0.6830\n",
            "Epoch 414/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6729 - accuracy: 0.6847\n",
            "Epoch 415/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6730 - accuracy: 0.6838\n",
            "Epoch 416/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6726 - accuracy: 0.6849\n",
            "Epoch 417/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6727 - accuracy: 0.6844\n",
            "Epoch 418/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6720 - accuracy: 0.6857\n",
            "Epoch 419/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6726 - accuracy: 0.6845\n",
            "Epoch 420/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6723 - accuracy: 0.6857\n",
            "Epoch 421/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6724 - accuracy: 0.6845\n",
            "Epoch 422/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6726 - accuracy: 0.6837\n",
            "Epoch 423/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6719 - accuracy: 0.6846\n",
            "Epoch 424/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6719 - accuracy: 0.6838\n",
            "Epoch 425/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6711 - accuracy: 0.6848\n",
            "Epoch 426/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6723 - accuracy: 0.6850\n",
            "Epoch 427/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6713 - accuracy: 0.6837\n",
            "Epoch 428/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6720 - accuracy: 0.6838\n",
            "Epoch 429/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6717 - accuracy: 0.6851\n",
            "Epoch 430/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6710 - accuracy: 0.6857\n",
            "Epoch 431/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6714 - accuracy: 0.6851\n",
            "Epoch 432/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 0.6716 - accuracy: 0.6856\n",
            "Epoch 433/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6707 - accuracy: 0.6850\n",
            "Epoch 434/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6709 - accuracy: 0.6852\n",
            "Epoch 435/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6711 - accuracy: 0.6860\n",
            "Epoch 436/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6704 - accuracy: 0.6852\n",
            "Epoch 437/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6706 - accuracy: 0.6852\n",
            "Epoch 438/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6697 - accuracy: 0.6857\n",
            "Epoch 439/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6705 - accuracy: 0.6858\n",
            "Epoch 440/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6702 - accuracy: 0.6856\n",
            "Epoch 441/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6696 - accuracy: 0.6872\n",
            "Epoch 442/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6702 - accuracy: 0.6858\n",
            "Epoch 443/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6691 - accuracy: 0.6857\n",
            "Epoch 444/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6705 - accuracy: 0.6860\n",
            "Epoch 445/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6701 - accuracy: 0.6863\n",
            "Epoch 446/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6692 - accuracy: 0.6867\n",
            "Epoch 447/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6692 - accuracy: 0.6864\n",
            "Epoch 448/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6695 - accuracy: 0.6855\n",
            "Epoch 449/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6689 - accuracy: 0.6873\n",
            "Epoch 450/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6688 - accuracy: 0.6865\n",
            "Epoch 451/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6693 - accuracy: 0.6848\n",
            "Epoch 452/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6685 - accuracy: 0.6872\n",
            "Epoch 453/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6685 - accuracy: 0.6881\n",
            "Epoch 454/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6686 - accuracy: 0.6864\n",
            "Epoch 455/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6680 - accuracy: 0.6879\n",
            "Epoch 456/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6679 - accuracy: 0.6886\n",
            "Epoch 457/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6688 - accuracy: 0.6873\n",
            "Epoch 458/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6676 - accuracy: 0.6874\n",
            "Epoch 459/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6678 - accuracy: 0.6862\n",
            "Epoch 460/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6683 - accuracy: 0.6874\n",
            "Epoch 461/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6669 - accuracy: 0.6890\n",
            "Epoch 462/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6675 - accuracy: 0.6885\n",
            "Epoch 463/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6682 - accuracy: 0.6871\n",
            "Epoch 464/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6680 - accuracy: 0.6874\n",
            "Epoch 465/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6667 - accuracy: 0.6877\n",
            "Epoch 466/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6671 - accuracy: 0.6885\n",
            "Epoch 467/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6672 - accuracy: 0.6870\n",
            "Epoch 468/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6665 - accuracy: 0.6880\n",
            "Epoch 469/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6674 - accuracy: 0.6875\n",
            "Epoch 470/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6668 - accuracy: 0.6869\n",
            "Epoch 471/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6663 - accuracy: 0.6894\n",
            "Epoch 472/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6664 - accuracy: 0.6892\n",
            "Epoch 473/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6664 - accuracy: 0.6890\n",
            "Epoch 474/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6668 - accuracy: 0.6880\n",
            "Epoch 475/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 0.6668 - accuracy: 0.6878\n",
            "Epoch 476/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6663 - accuracy: 0.6897\n",
            "Epoch 477/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6659 - accuracy: 0.6891\n",
            "Epoch 478/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6664 - accuracy: 0.6873\n",
            "Epoch 479/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6656 - accuracy: 0.6889\n",
            "Epoch 480/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6657 - accuracy: 0.6884\n",
            "Epoch 481/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6655 - accuracy: 0.6890\n",
            "Epoch 482/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6659 - accuracy: 0.6888\n",
            "Epoch 483/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6652 - accuracy: 0.6892\n",
            "Epoch 484/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6656 - accuracy: 0.6889\n",
            "Epoch 485/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6662 - accuracy: 0.6884\n",
            "Epoch 486/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6655 - accuracy: 0.6876\n",
            "Epoch 487/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6647 - accuracy: 0.6893\n",
            "Epoch 488/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6652 - accuracy: 0.6893\n",
            "Epoch 489/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 0.6651 - accuracy: 0.6890\n",
            "Epoch 490/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6645 - accuracy: 0.6903\n",
            "Epoch 491/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6644 - accuracy: 0.6901\n",
            "Epoch 492/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6646 - accuracy: 0.6901\n",
            "Epoch 493/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6644 - accuracy: 0.6898\n",
            "Epoch 494/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6641 - accuracy: 0.6904\n",
            "Epoch 495/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6643 - accuracy: 0.6903\n",
            "Epoch 496/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6641 - accuracy: 0.6884\n",
            "Epoch 497/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6646 - accuracy: 0.6899\n",
            "Epoch 498/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6640 - accuracy: 0.6892\n",
            "Epoch 499/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6641 - accuracy: 0.6902\n",
            "Epoch 500/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 0.6639 - accuracy: 0.6909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bf53a63a0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos las predicciones para train y vemos cómo performa."
      ],
      "metadata": {
        "id": "GpNHjUe4MNUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clasificar_propiedad(model, entrada):\n",
        "  prediccion = model.predict(entrada)\n",
        "  arg_max = np.argmax(prediccion, axis=1)\n",
        "  return arg_max"
      ],
      "metadata": {
        "id": "NZTWJoEfMhn2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clasificar_propiedad(best_model, x_train_clasificacion)\n",
        "graficar_matriz_de_confusion(y_train_clasificacion, y_pred, outputs.keys())\n",
        "imprimir_metricas_de_clasificacion(y_train_clasificacion, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "lJMdM25jMp3j",
        "outputId": "1dd32a63-722b-4026-fc7f-dc99ecf82eea"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2163/2163 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAJcCAYAAAA1u1ZTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZxWZd3H8c9vGNn3xY1FQVFEzdxNc899gcpMrdxIKs00Lc0lTc1KyyxNM0rcMtfHXDE1c81EcVfUxB1ERTYREBy4nj/uA90iwxmWOXNgPu/ndV4z5zrbde588fzme67r3JFSQpIkSSqLmqbugCRJklTNAlWSJEmlYoEqSZKkUrFAlSRJUqlYoEqSJKlULFAlSZJUKhaokpaJiPhGRNy9DM5zeUT8fFn0aVmIiDYRcVtETI2IG5biPAv9fCKif0Q8ExFrLF1PJWnFYYEqrcAi4o2ImB0R3RdofyoiUkSs2YBzrJntW7uo/VJKV6eUdl26HpfSfsAqQLeU0teW9CQL+3wiohMwDNgvpfTm0nVTklYcFqjSiu914MB5KxGxIdB2WV4gr3hdzq0B/DelVLesT5xSmppS2jGl9MqyPrckLc8sUKUV31XAwVXrhwBXVu8QEXtlqeqHEfF2RPysavOD2c8pEfFRRHwhIg6NiH9HxPkRMRH4Wdb2cHa+E7J95y2fRMTlC+tcRGwcEU9GxLSIuA5ovcD2vSPi6YiYEhGPRMTn6rvRiFg/Iu6JiEkR8V5EnJy1t4qI30XEO9nyu4holW3bISLGRsTxEfF+RIyPiMOybWcApwFfz+5jSET8LCL+WnXNTyXM2efwWnY/r0fEN6raH646buuIeDwbOvB4RGxdte3+iDgr+4ynRcTdC6bgkrQis0CVVnyPAh0jYr2IaAEcAPx1gX2mUyliOwN7Ad+LiMHZtu2yn51TSu1TSv/J1rcEXqPy+Pvs6pOllM7N9m0PrAdMAK5bsGMR0RK4mUoR3RW4Afhq1faNgeHAd4BuwJ+AW+cVlwucqwPwT+AfwOrA2sC92eZTgK2AzwMbAVsAp1YdvirQCegJDAEuioguKaXTgV8A12X3c+mC112gD+2AC4A9UkodgK2BpxeyX1fgjmzfbsBvgTsiolvVbgcBhwErAy2BHy3q2pK0IrFAlZqHeSnqLsCLwLjqjSml+1NKz6WU5qaUngWuAbbPOec7KaULU0p1KaWZC9shItpQKUB/n1K6cyG7bAWsBPwupfRJSulG4PGq7UOBP6WURqaU5qSUrgBmZcctaG/g3ZTSeSmlj1NK01JKI7Nt3wDOTCm9n1KaAJwBfKvq2E+y7Z+klEYAHwHr5tx/feYCG0REm5TS+JTSCwvZZy/glZTSVdnndw3wErBP1T6XpZT+m32211MpriWpWbBAlZqHq6gkcoeywON9gIjYMiLui4gJETEV+C6Q90j57QZc91Lg5ZTSOfVsXx0Yl1JKVW3Vk4XWAI7PHu9PiYgpQO/suAX1Bl5dxHWqz/vmAueYuMAY0xlA+3rOVa+U0nTg61Q+v/ERcUdEDGhAf+b1qWfV+rtL2x9JWl5ZoErNQDZD/HVgT+CmhezyN+BWoHdKqRNwCRDzDq/vtIu6ZkT8BFiHyiPz+owHekZEVLX1qfr9beDslFLnqqVtljgu6G2gXz3XeYdKsVt9jXcW1f9FmM6nJ5mtWr0xpXRXSmkXYDUqqeifG9CfeX0at5B9JanZsUCVmo8hwE5ZyregDsCklNLHEbEFlbR1nglUHlvXV/x9RkTsAfwA+HJ9j/8z/wHqgB9ExEoR8RUq40Pn+TPw3SzhjYhol03o6rCQc90OrBYRx2aTojpExJbZtmuAUyOiRzbZ6DQ+Ow63oZ4GtouIPtlrok6quu9VImJQNhZ1FpWhAnMXco4RwDoRcVBE1EbE14GB2T1IUrNngSo1EymlV1NKo+rZfCRwZkRMo1K8XV913Awqk6D+nT1mX9j4zwV9HegBvFg1k/+ShfRpNvAVKkMPJmXH3VS1fRRwBPAHYDIwJtt3Yfc3jcoY232oPB5/Bdgx2/xzYBTwLPAc8GTWtthSSvdQmfD1LPAEny4qa4DjqCSkk6iM4/3eQs4xkcqY2eOBicAJwN4ppQ+WpE+StKKJTw/9kiRJkpqWCaokSZJKxQJVkiRJpWKBKkmSpFKxQJUkSVKp1DZ1B+rT5uArnL2l5d7kywbn7yQtB56a+GxTd0FaJr6w8raRv1fjarPjmYXWODPvO63J73lxmaBKkiSpVCxQJUmSVCqlfcQvSZK0Qorl7ol74UxQJUmSVComqJIkSUWqMR/M4yckSZKkUjFBlSRJKpJjUHOZoEqSJKlUTFAlSZKKZIKaywRVkiRJpWKCKkmSVKQwH8zjJyRJkqRSMUGVJEkqUo1jUPOYoEqSJKlULFAlSZJUKj7ilyRJKpKvmcplgipJkqRSMUGVJEkqkq+ZyuUnJEmSpFIxQZUkSSqSY1BzmaBKkiSpVExQJUmSiuSL+nOZoEqSJKlUTFAlSZKK5Cz+XH5CkiRJKhUTVEmSpCI5iz+XCaokSZJKxQRVkiSpSI5BzeUnJEmSpFIxQZUkSSqS70HNZYIqSZKkUrFAlSRJUqn4iF+SJKlIvmYqlwmqJEmSSsUEVZIkqUi+ZiqXn5AkSZJKxQRVkiSpSI5BzWWCKkmSpFIxQZUkSSqSL+rPZYIqSZKkUjFBlSRJKpKz+HP5CUmSJKlUTFAlSZKK5Cz+XCaokiRJKhUTVEmSpCKZoOYyQZUkSVKpmKBKkiQVqcZ8MI+fkCRJkkrFAlWSJEml4iN+SZKkIjlJKpcJqiRJkkrFBFWSJKlIJqi5TFAlSZJUKiaokiRJRQrzwTx+QpIkSSoVE1RJkqQi1TgGNY8JqiRJkkrFAlWSJKlIEcUuud2J4RHxfkQ8v0D70RHxUkS8EBHnVrWfFBFjIuLliNitqn33rG1MRPykqr1vRIzM2q+LiJZ5fbJAlSRJat4uB3avboiIHYFBwEYppfWB32TtA4EDgPWzYy6OiBYR0QK4CNgDGAgcmO0LcA5wfkppbWAyMCSvQxaokiRJRYqaYpccKaUHgUkLNH8P+FVKaVa2z/tZ+yDg2pTSrJTS68AYYItsGZNSei2lNBu4FhgUEQHsBNyYHX8FMDivTxaokiRJK7CIGBoRo6qWoQ04bB1g2+zR/AMRsXnW3hN4u2q/sVlbfe3dgCkppboF2hfJWfySJElFKvibpFJKw4Bhi3lYLdAV2ArYHLg+Ivot674t6uKSJElStbHATSmlBDwWEXOB7sA4oHfVfr2yNuppnwh0jojaLEWt3r9ePuKXJEkqUk0UuyyZm4EdASJiHaAl8AFwK3BARLSKiL5Af+Ax4HGgfzZjvyWViVS3ZgXufcB+2XkPAW7Ju7gJqiRJUjMWEdcAOwDdI2IscDowHBievXpqNnBIVmy+EBHXA6OBOuColNKc7DzfB+4CWgDDU0ovZJc4Ebg2In4OPAVcmtcnC1RJkqRmLKV0YD2bvlnP/mcDZy+kfQQwYiHtr1GZ5d9gFqiSJElFasCrn5o7PyFJkiSVigmqJElSkQp+zdTyyARVkiRJpWKCKkmSVKAwQc1lgipJkqRSMUGVJEkqkAFqPhNUSZIklYoJqiRJUoFiyb9+tNkwQZUkSVKpmKBKkiQVyAA1nwmqJEmSSsUEVZIkqUC+BzWfCaokSZJKxQRVkiSpQAao+UxQJUmSVCqNmqBGxErA94DtsqYHgEtSSp805nUlSZK0/GrsR/x/BFYCLs7Wv5W1fbuRrytJklRKTpLK19gF6uYppY2q1v8VEc808jUlSZK0HGvsAnVORKyVUnoVICL6AXMa+ZqSJEmlZYKar7EL1B8D90XEa0AAawCHNfI1m51Lvr01e3y+FxM+/JjNTr51fvv3dhnAd3YewJy5iX88M5ZTrnuCndZfjbP235SWtTXMrpvLydeO4oEX3wVgvy3X5IR9NqRFTQ13Pv02p17/JAB9urXjkm9vQ/cOrZg8fTaHX/IQ4ybPaJJ7VfPzxutvcsJxJ89fHzv2HY48eijvvzeBB+5/iJVWWolevXty5tmn0bFjBwD++/IrnPWzX/LRR9Opqanhb9dfTqtWrZrqFtTMHf+1E2nTtjVRU0OLFjX87C8/nb/tzmvv4rqLbuDC286nQ+cOPHL3o4y4+k4AWrdtzcHHf5M+a/dm9qxP+OXR51A3u445c+ay+Q6b8uUhg5rqlqRG16gFakrp3ojoD6ybNb2cUprVmNdsjq566FUuuecl/vKdL85v2269Vdl7k95sceqtzK6bS48OrQGY+NEs9jv/XsZPmcnAnp257ce7sNaxN9C1fSt+ccCmbH3a7XwwbRZ/HroNOwxclftHv8svD9yMq//9Klc//Crbr7cqZ+6/CUP+9HBT3a6amTX7rsH1f78agDlz5rDLDnux08478MYbb/KDHx5JbW0t5593IZf++XJ+ePzR1NXVcfKJp3P2r37GugPWYcqUKdTW+kY9Na0Tf/8jOnTu8Km2ie9N4oXHRtNtla7z23qs1p2T/nAC7Tq049lHn+Pyc6/ktGGnsFLLWk783Y9o3bY1dXV1/OLIc9hwqw1Ye/21ir4VLQMGqPka5TVTEbFT9vMrwF7A2tmyV0R8OSK2j4gWjXHt5ujfL7/HpOmfrvuH7rQuv7n9eWbXzQVgwrSPAXjmzUmMnzITgNHjptC6ZQta1tbQt0d7xrw7jQ+mVc7zr+fHM3jzNQAYsHpnHhg9HoAHXnyXvTfpXch9SQsa+ejj9O7Ti9V7rsbW22w1v/D83EYb8P677wPwn3+PpP86a7PugHUA6Ny5My1a+M+NyueaC69j/yP3+1S10n/DtWnXoR0Aa63fj0kTJgOVR8Kt21aChjl1c5hTN4fAKkcrrsaKFbYH/gXsU8/2bsCpwC6NdP1mb+1VO7LNOitzxn4b8/EnczjpmlE88frET+3z5c3X4Ok3JzK7bi6vvjeNdVbrSJ/u7Rg3aQb7btqHlWorf7889/YkBm22Bhfd/SKDNutDxzYt6dq+FZM+MgxXsf4x4h5233PXz7TffNNt7LZ75Z+TN998i4jgu0cczeRJU9h9z104bMjBRXdVmi8i+M1x50PAjoO2Z4d9t+fJh56iS4/O9Fm7/j/4H7z9YT635Qbz1+fOmcvp3z6L98e9z85f3pG11u9XRPfVCByDmq9RCtSU0unZz3rHm0bEpQtpGwoMBajd8lBq19mhMbrXLNS2CLq2b8V2Z4xgs37d+ev3t2e942+av329np35+f6bsvev7wFgyozZ/ODyR/nrUdszNyUefWUC/VauPI466ZpRnH/wlnxz27X490vvMW7SdObMndsk96Xm65PZn/DAfQ9yzA+P/FT7ny8ZTosWLdhrn92BSrr01JNP87frr6B169YMPfxIBg4cwJZf2KIpui1xykUn0qVHFz6c/CG//uFvWa3Patx+1Qh+9Nsf1nvMi0++xIN3PMQpF/1kfltNixrOuux0pk+bwYWnXMTY18bRq1/PIm5BKlyjD8yKiL2A9YHW89pSSmemlIYsuG9KaRgwDKDNwVekxu7bimzcpBncPOotAEa99gFz50L3Dq34YNosenZpy3XH7MC3hz3E6+9Pm3/MiKfHMuLpsQAcvkN/5syt/E8wfspMDrjgfgDatapl8OZrMHWG37WgYj380CMMGDiAbt27zW+75e+38+ADDzNs+MXzE4mVV12ZTTfbmC5dOgPwxe224cXRL1ugqsl06dEFgI5dOrLJdhvz0tMvM2H8B/z0sDMAmDxhMqcPOYvThp1C526deHvM2ww/5wqO//UxtO/U/jPna9ehLettPIDnRj5vgbqcCr/HM1ejfkQRcQnwdeBoKrP4v0ZlJr8a2W1PvMX2660KVB73t6yt4YNps+jUdiVuOn5nfnr9k/znlQmfOmbeRKrObVsydOcBXPbAKwB0a99q/hCpH++zIVc8OKa4G5Eyd464mz2qHu//+6H/cPmlV/H7i86jTZv5f/+yzTZb8cp/X2XmzI+pq6vjicefpN/afZuiyxKzZs5i5oyP5//+wuOj6bteXy687XzOu+EczrvhHLr06MIZl/6Uzt06MfG9iVx46sUMPXUIq/ZZdf55Ppw8jenTKm9PmT1rNi+MGs1qVdulFU1jJ6hbp5Q+FxHPppTOiIjzgDsb+ZrNzhXf245t11uF7u1bM+Z3+3HWTU9zxYNj+NO3t2bUL/Zldt1cvj2sMuv+u19aj7VW6cBJgzbipEGV71DY59x7mDDtY37zzS3YsE/lL/1f3vwMY979EKi8EeDMr21CIvHwS+9x7JUjm+ZG1WzNmDGTRx8ZyU9/dtL8tl/+/NfM/mQ23x3yfQA23GgDfvqzk+jYqSPfOuQgDtr/ECKCbbfbmu22/2J9p5Ya1dTJH3LhyRcBMGfOXLbaZYtPjStd0C2X3cZHU6dz5W8rb66Y91qqqROn8OdfDGfunLmklNhix835/DYb1XselZtjUPNFSo33JD0iRqaUtoyIR4GvABOBF1JKa+cd6yN+rQgmXza4qbsgLRNPTXy2qbsgLRNfWHnbJq8OVz7x9kJrnPfP2bvJ73lxNXaCentEdAbOBZ7I2v7SyNeUJEkqLQPUfI1doP4G+B6wLfAf4CHgj418TUmSJC3HGrtAvQKYBlyQrR8EXAns38jXlSRJKqUaI9RcjV2gbpBSGli1fl9EjG7ka0qSJGk51tgF6pMRsVVK6VGAiNgSGNXI15QkSSotZ/Hna5QCNSKeAxKwEvBIRLyVra8BvNQY15QkSdKKobES1L0b6bySJElawTVKgZpSerMxzitJkrS88wl/Pr8NVpIkSaXS2JOkJEmSVMVJUvlMUCVJklQqJqiSJEkFMkDNZ4IqSZKkUjFBlSRJKlDUGKHmMUGVJElSqZigSpIkFcgxqPlMUCVJklQqJqiSJEkF8j2o+UxQJUmSVComqJIkSQUyQM1ngipJkqRSMUGVJEkqkGNQ85mgSpIkqVQsUCVJklQqPuKXJEkqkI/485mgSpIkNWMRMTwi3o+I5xey7fiISBHRPVuPiLggIsZExLMRsUnVvodExCvZckhV+6YR8Vx2zAXRgArdAlWSJKlANVHs0gCXA7sv2BgRvYFdgbeqmvcA+mfLUOCP2b5dgdOBLYEtgNMjokt2zB+BI6qO+8y1PvMZNajbkiRJWiGllB4EJi1k0/nACUCqahsEXJkqHgU6R8RqwG7APSmlSSmlycA9wO7Zto4ppUdTSgm4Ehic1yfHoEqSJBUoGhhrLrPrRQylknbOMyylNCznmEHAuJTSMws8ke8JvF21PjZrW1T72IW0L5IFqiRJ0gosK0YXWZBWi4i2wMlUHu83CR/xS5IkFSii2GUJrAX0BZ6JiDeAXsCTEbEqMA7oXbVvr6xtUe29FtK+SBaokiRJmi+l9FxKaeWU0poppTWpPJbfJKX0LnArcHA2m38rYGpKaTxwF7BrRHTJJkftCtyVbfswIrbKZu8fDNyS1wcf8UuSJBWobO9BjYhrgB2A7hExFjg9pXRpPbuPAPYExgAzgMMAUkqTIuIs4PFsvzNTSvMmXh1J5U0BbYA7s2WRLFAlSZKasZTSgTnb16z6PQFH1bPfcGD4QtpHARssTp8sUCVJkgpUsgC1lByDKkmSpFIxQZUkSSpQ2caglpEJqiRJkkrFBFWSJKlAJqj5TFAlSZJUKhaokiRJKhUf8UuSJBXIJ/z5TFAlSZJUKiaokiRJBYoaI9Q8JqiSJEkqFRNUSZKkAjkGNZ8JqiRJkkrFBFWSJKlANUaouUxQJUmSVComqJIkSQXyq07zmaBKkiSpVExQJUmSCmSAms8EVZIkSaVigipJklQgv0kqnwmqJEmSSsUEVZIkqUDO4s9ngipJkqRSsUCVJElSqfiIX5IkqUA+4c9ngipJkqRSMUGVJEkqkJOk8pmgSpIkqVRMUCVJkgrki/rzmaBKkiSpVExQJUmSCuQQ1HwmqJIkSSoVE1RJkqQCOYs/nwmqJEmSSsUEVZIkqUA1Jqi5TFAlSZJUKiaokiRJBTJAzWeCKkmSpFIxQZUkSSqQ3ySVzwRVkiRJpWKBKkmSpFLxEb8kSVKBfFF/PhNUSZIklYoJqiRJUoEMUPOZoEqSJKlUTFAlSZIK5BjUfCaokiRJKhUTVEmSpAL5ov58JqiSJEkqFRNUSZKkAjkENZ8JqiRJkkqltAnqpOGDmroL0lLr8qXfN3UXpGXi8Zv2buouSCsMZ/HnM0GVJElSqZQ2QZUkSVoRmaDmM0GVJElqxiJieES8HxHPV7X9OiJeiohnI+LvEdG5attJETEmIl6OiN2q2nfP2sZExE+q2vtGxMis/bqIaJnXJwtUSZKkAtVEsUsDXA7svkDbPcAGKaXPAf8FTgKIiIHAAcD62TEXR0SLiGgBXATsAQwEDsz2BTgHOD+ltDYwGRiS+xk1qNuSJElaIaWUHgQmLdB2d0qpLlt9FOiV/T4IuDalNCul9DowBtgiW8aklF5LKc0GrgUGRWU8w07AjdnxVwCD8/pkgSpJkrQCi4ihETGqahm6mKc4HLgz+70n8HbVtrFZW33t3YApVcXuvPZFcpKUJElSgYr+qtOU0jBg2JIcGxGnAHXA1cu0UzksUCVJkvQZEXEosDewc0opZc3jgN5Vu/XK2qinfSLQOSJqsxS1ev96+YhfkiSpQBFR6LKEfdwdOAHYN6U0o2rTrcABEdEqIvoC/YHHgMeB/tmM/ZZUJlLdmhW29wH7ZccfAtySd30LVEmSpGYsIq4B/gOsGxFjI2II8AegA3BPRDwdEZcApJReAK4HRgP/AI5KKc3J0tHvA3cBLwLXZ/sCnAgcFxFjqIxJvTSvTz7ilyRJKlDZ3tOfUjpwIc31FpEppbOBsxfSPgIYsZD216jM8m8wE1RJkiSVigmqJElSgfyq03wmqJIkSSoVE1RJkqQCFf0e1OWRCaokSZJKxQRVkiSpQA5BzWeCKkmSpFIxQZUkSSqQs/jzmaBKkiSpVExQJUmSCmSCms8EVZIkSaVigSpJkqRS8RG/JElSgXxPfz4TVEmSJJWKCaokSVKBIlJTd6H0TFAlSZJUKiaokiRJBfItU/lMUCVJklQqJqiSJEkFqnEMai4TVEmSJJWKCaokSVKBHIKazwRVkiRJpWKCKkmSVCDHoOYzQZUkSVKpmKBKkiQVyPeg5jNBlSRJUqmYoEqSJBXIBDWfCaokSZJKxQJVkiRJpeIjfkmSpAL5mql8JqiSJEkqFRNUSZKkAjlHKp8JqiRJkkrFBFWSJKlAjkHNZ4IqSZKkUjFBlSRJKpAv6s9ngipJkqRSMUGVJEkqUDgGNZcJqiRJkkrFBFWSJKlApoP5/IwkSZJUKiaokiRJBXIMaj4TVEmSJJWKCaokSVKBanwPai4TVEmSJJWKBaokSZJKxUf8kiRJBXKSVD4TVEmSJJWKCaokSVKBnCSVzwRVkiRJpWKCKkmSVKDAMah5TFAlSZJUKiaokiRJBQrHoOYyQZUkSVKp5BaoEXFMRHSMiksj4smI2LWIzkmSJK1oaiIVuuSJiOER8X5EPF/V1jUi7omIV7KfXbL2iIgLImJMRDwbEZtUHXNItv8rEXFIVfumEfFcdswFEfkZckMS1MNTSh8CuwJdgG8Bv2rAcZIkSSq/y4HdF2j7CXBvSqk/cG+2DrAH0D9bhgJ/hEpBC5wObAlsAZw+r6jN9jmi6rgFr/UZDSlQ51W5ewJXpZReqGqTJEnSYogodsmTUnoQmLRA8yDgiuz3K4DBVe1XpopHgc4RsRqwG3BPSmlSSmkycA+we7atY0rp0ZRSAq6sOle9GlKgPhERd1MpUO+KiA7A3AYcJ0mSpCYWEUMjYlTVMrQBh62SUhqf/f4usEr2e0/g7ar9xmZti2ofu5D2RWrILP4hwOeB11JKMyKiG3BYA46TJEnSAhoyLnRZSikNA4YtxfEpothO5xaoKaW5EdELOCgb0/pASum2Ru+ZJEmSmsp7EbFaSml89pj+/ax9HNC7ar9eWds4YIcF2u/P2nstZP9Fasgs/l8BxwCjs+UHEfGLvOMkSZL0WVHwsoRuBebNxD8EuKWq/eBsNv9WwNRsKMBdwK4R0SWbHLUrcFe27cOI2CqbvX9w1bnq1ZBH/HsCn08pzQWIiCuAp4CTG3yLkiRJKqWIuIZK+tk9IsZSmY3/K+D6iBgCvAnsn+0+gkptOAaYQTbsM6U0KSLOAh7P9jszpTRv4tWRVN4U0Aa4M1sWqaHfJNWZ/83u6tTAYyRJklRyKaUD69m080L2TcBR9ZxnODB8Ie2jgA0Wp08NKVB/ATwVEfdRSYq343/vwpIkSdJi8KtO8y2yQI2IGiqvlNoK2DxrPjGl9G5jd0ySJEnN0yIL1GwG/wkppeupDIqVJEnSUij6NVPLo4Y84v9nRPwIuA6YPq+xauDrIkXERsC22epDKaVnFruXkiRJajYaUqB+PftZPSA2Af3yDoyIY6h89+pNWdNfI2JYSunCxeqlJEnSCsIxqPka8qL+vktx/iHAliml6QARcQ7wH8ACVZIkSQuVW6BGRFvgOKBPSmloRPQH1k0p3d6A8wcwp2p9Dkv1zlhJkqTlWw2OQc3TkEf8lwFPAFtn6+OAG4CGFKiXASMj4u/Z+mDg0sXtpCRJkpqPhhSoa6WUvh4RBwKklGZkX1WVK6X024i4H/hi1nRYSumpJeuqJEnS8s8xqPkaUqDOjog2VCZGERFrAbMWdUBEdEwpfRgRXYE3smXetq4NfQOAJEmSmp+GFKinA/8AekfE1cA2wKE5x/wN2JvK0IDqgRZBA98AIEmStCIK34OaqyGz+O+JiCepfJtUAMeklD7IOWbv7OfSvAFAkiRJzVC9BWpEbLJA0/jsZ5+I6JNSenIxjv2URR2rZevqq67lphtvIaXEV/YbxDcPPpCpU6Zywo9O5Z1x77B6z9X59Xln07FTR6ZN+4hTTjydd8e/S92cORx82DcY/OV9mvoW1ExccsI+7LHVOkyYMp3NDr8EgKtO+yr9e3cDoHP71kz56GO2OmIYK9XW8Ifj9maTdVdjbkr86AN+Rt0AACAASURBVMK7eOiZNwHYeJ3VGHbivrRptRJ3jXyF4y+8C4DPrbUKFx63F61a1lI3Zy7H/m4Eo156p2luVs3KnDlzOfGwk+naoysnn3cCvzvtD7z60mu0qG1B/4Fr8Z2ffJva2lqef2I055zwG1ZefWUAttxhc/Yf8lU+eG8iF5xxMVMnTYWAXQbvzN5f36OJ70pLo8YxqLkWlaCel/1sDWwGPEMlQf0cMAr4QiMdq2VkzCuvctONt/DXay9jpZVqOeo7x7Ld9l/k/264mS233IzDjziE4X++guF/uZJjj/8+111zI/3W6ssFF5/HpEmTGbzX/uy11+6s1HKlpr4VNQNX/eMZLvn74/zlpMHz27515v/N//1X39uFqdMrw98P37vyN/DmQ/5Ej85tufmcg/jid/9CSnDBsXty1G9u57EXx3Hzrw5i1y3W5u7HxnD2d77E2Vc8yN2PjWG3Ldfm7O98id1+eGWxN6lm6Y7r7qTnmj2ZOX0mANvuvg3HnFH57pvzT7uQf95yH7t/dRcA1vv8AE4+74RPHd+iRQ2H/uCb9BvQl5nTZ/LjQ09moy02pHffXsXeiFSgmvo2pJR2TCntSCU53SSltFlKaVNgYyqvmqrX0hyrZee1195gw8+tT5s2ramtrWXTzTbm3n/ez/33Pcg+g/cCYJ/Be3Hfvx4AKrMKp0+fQUqJmTNm0qlTR1rUtmjKW1Az8u9n32LShzPr3f7VHQZy/b3PAzBgjR7c/9TrAEyYMoOpH81i03VXZ9Wu7enQrhWPvVj5Z+Zvdz/DPl9cF6gMfu/YriUAndq1YvzEaY14N1LFxPcn8uQjT/GlfXec37bp1hsTEUQE/QeuzcT3Fz1vuEv3LvQbUBkx16ZdG3qt2ZNJOceo3CJSocvyqN4Ctcq6KaXn5q2klJ4H1mvg+ZfmWC2ltdfux5NPPM2UKVOZOfNjHn7oEd579z0mTpxEjx7dAejevRsTJ1b+oTvgoK/x+muvs8sOe7Hf4IP48Uk/pKamIf+JSI1rm8/14b3J03l1XOW/1edefY+9t16XFjXBGqt2ZuN1VqPXyh1ZvXsHxk34cP5x4yZMY/XuHQD48R/u4hff2YVXrjuGX353F07787+a5F7UvAw//0q+9f2DiPjsv6V1dXU8cOdDbPyFjea3vfzcKxz3zRP5+bG/4q3X3v7MMe+/M4HX//sG/TdYu1H7LTW1hszifzYi/gL8NVv/BvBsA8+/WMdGxFBgKMCFF5/PkCMObeBltDD91urLYUMO5ntHHE2bNm1Yd8A6nyk45/0VD/DIw4+y7oB1+PNlF/P2W2P57hFHs8mmn6d9+/ZN0X1pvv132oAbsvQU4IoRTzGgT3f+/acjeOu9qTz6/NvMmbPolGDooE054eK7uPnBl/jqDgP544/3Ya8f/XWRx0hLY9TDT9KpS0fWGtCP558Y/Zntfz53OAM3HsDAzw8AoN+ANbnk5gtp07Y1TzzyFOec8FsuuvH8+fvPnPExvz7pfA479mDatmtb2H1o2TP6ydeQz+gw4AXgmGwZnbU1xGIdm1Ialg0H2MzidNn48lf35ZobrmT4lX+iQ8cOrLFmH7p168qECZUXMUyY8AFdu3YB4Jabb2fnXXYgIuizRm969lyd1197sym7L9GiJhi07QBuvO+F+W1z5iZOuPhutjpiGPufeh2d27fmlbETeeeDafTs0XH+fj17dOCdDyqP8r+x60bc/OBLAPzf/aPZbEDPYm9Ezc5Lz77M4w89yXcHH835P72A50a9wO9P/wMA1//lRqZOmcahx3xr/v5t27WlTdvWQGUYwJy6Oj6cUnkiUFdXx69POp9td9uGrXbcovibkQrWkNdMfQycny2LJaX0cURcAoxIKb28BP3TUpo0cRJdu3Vl/Dvv8q9/3s+Vf7uUcePe4bab7+DwIw7htpvvYIcdtwNgtdVWZeSjo9hk042Z+MFE3njjLXr19v+Jq2nttGk//vv2RMZ98L8xo21a1RIRzPj4E3batB91c+by0puVP7qmTZ/FFuv15LEXx3HQrhvxx78/BsD4idPYdqM1eOiZN9lhk76MGTexSe5Hzcc3jzyQbx55IADPPzGaW/92O8ec8X3+ecu/eHrks5x+4amfeqo1eeIUOnftRETwygtjSCnRoVMHUkpcfPYweq25OvsetFdT3Y5UqNwCNSL6A78EBlKZlQ9ASin3ZfsRsS/wa6Al0DciPg+cmVLad4l7rMVy/LE/YeqUqdTW1nLSqT+mY8cOHP7tQzjhuJP5+023svrqq3HueWcDcMR3D+e0U85kv8EHkVLi2OOOokuXzk18B2ourjj1K2z7+TXo3qktY64/lrMuv58rRjzN13Zaf/7kqHl6dG7Hbed+g7kp8c4H0xjyy5vnbzvmdyMY9pNBtGlZy92PjeGukWMAOOo3t/Pro3ejtkUNs2bP4fvn3VHo/Unz/OncS+mxandOPuI04H+vk/rPv0Zy10330KJFC1q2askPz/oBEcGLT7/EA3c+RJ+1enP8t34CwEHf+zqbbr1xU96GlsLyOnGpSJHSoj+kiHiYyrdJnQ/sQ+URfU1K6bTck0c8AewE3J9S2jhrey6ltGHesTPrpvi/npZ7XXe5oKm7IC0Tj9+0d1N3QVomNuiySZO/hfS0Jx8utMY5c5MvNvk9L66GjEFtk1K6l0ox+2ZK6WdAQ58xfJJSmrpAm4WnJElqtmoKXpZHDZnFPysq78d4JSK+T+U9pg2d1v1CRBwEtMiGCvwAeGTJuipJkqTmoCGF9TFAWyrF5abAt4BDGnj+o4H1gVnA34Cp2fkkSZKaJV/Un68hs/gfz379iIa/XmqegdlSmy2DgH2pfOWpJEmS9Bn1FqgRcRuLGC/awJn4VwM/Ap4H5i527yRJklYwy92MpSawqAT1N9nPrwCr8r9vgzoQeK+B55+QUrptCfsmSZKkZqjeAjWl9ABARJyXUtqsatNtETGqgec/Pfuq03upjEOdd+6blqSzkiRJy7ua5XRcaJEaMou/XUT0Sym9BhARfYF2DTz/YcAAYCX+94g/ARaokiRJWqiGFKjHAvdHxGtUhk2sAQxt4Pk3Tymtu6SdkyRJWtE4BjXfIgvU7P2nnYD+VJJQgJdSSrPqP+pTHomIgSml0UvRR0mSJDUjiyxQU0pzI+KElNL1wDNLcP6tgKcj4nUqY1Cjctrka6YkSVKz5BjUfA15xP/PiPgRcB0wfV5jSmlSA47dfUk7JkmSpOapIQXq17OfR1W1JaBf3oEppTeXpFOSJEkrqnAQaq6GfJNU3yI6IkmSJAHU5O0QEW0j4tSIGJat94+IvRu/a5IkSWqOcgtU4DJgNrB1tj4O+Hmj9UiSJGkFFgUvy6OGFKhrpZTOBT4BSCnNYPm9X0mSJJVcQyZJzY6INlQmRhERa1H1taWSJElqOF8zla/eAjUiLgKuAX4G/APoHRFXA9sAhxbROUmSJDU/i0pQ/wv8GlgNuAf4J/AkcExK6YMC+iZJkrTCcZxkvnrHoKaUfp9S+gKwPTAG+ApwHnBkRKxTUP8kSZLUzOROkkopvZlSOieltDFwIPBl4MVG75kkSdIKqCZSocvyqCHvQa2NiH2y8ad3Ai9TSVMlSZKkZW5Rk6R2oZKY7gk8BlwLDE0pTS+ob5IkSSscx6DmW9QkqZOAvwHHp5QmF9QfSZIkNXP1FqgppZ2K7IgkSVJzEMvpuNAiNeSbpCRJkqTCNOSbpCRJkrSMmA7m8zOSJElSqZigSpIkFcgxqPlMUCVJklQqFqiSJEkqFR/xS5IkFch0MJ+fkSRJkkrFAlWSJKlAEanQJb8/8cOIeCEino+IayKidUT0jYiRETEmIq6LiJbZvq2y9THZ9jWrznNS1v5yROy2NJ+RBaokSVIzFRE9gR8Am6WUNgBaAAcA5wDnp5TWBiYDQ7JDhgCTs/bzs/2IiIHZcesDuwMXR0SLJe2XBaokSVKBagpeGqAWaBMRtUBbYDywE3Bjtv0KYHD2+6BsnWz7zhERWfu1KaVZKaXXgTHAFg39TBZkgSpJkrQCi4ihETGqahk6b1tKaRzwG+AtKoXpVOAJYEpKqS7bbSzQM/u9J/B2dmxdtn+36vaFHLPYnMUvSZJUoKJf1J9SGgYMW3hfoguV9LMvMAW4gcoj+iZlgipJktR8fQl4PaU0IaX0CXATsA3QOXvkD9ALGJf9Pg7oDZBt7wRMrG5fyDGLzQJVkiSpQFHwkuMtYKuIaJuNJd0ZGA3cB+yX7XMIcEv2+63ZOtn2f6WUUtZ+QDbLvy/QH3hscT6Xaj7ilyRJaqZSSiMj4kbgSaAOeIrKcIA7gGsj4udZ26XZIZcCV0XEGGASlZn7pJReiIjrqRS3dcBRKaU5S9ovC1RJkqQC1RQ8BjVPSul04PQFml9jIbPwU0ofA1+r5zxnA2cviz75iF+SJEmlYoIqSZJUoGjAwNDmzgRVkiRJpWKCKkmSVKAayjUGtYxMUCVJklQqFqiSJEkqFR/xS5IkFchJUvlMUCVJklQqJqiSJEkFMkDNZ4IqSZKkUjFBlSRJKlDZvuq0jExQJUmSVComqJIkSQVyDGo+E1RJkiSVigmqJElSgRyDms8EVZIkSaVigipJklQgx6DmM0GVJElSqZigSpIkFSgcg5rLBFWSJEmlYoIqSZJUINPBfH5GkiRJKhULVEmSJJWKj/glSZIKFOGLpvKYoEqSJKlUTFAlSZIKZH6azwRVkiRJpWKCKkmSVCDHoOYzQZUkSVKpmKBKkiQVyPw0nwmqJEmSSsUEVZIkqUBhhprLBFWSJEmlYoIqSZJUICfx5zNBlSRJUqmYoEqSJBWoxjGouUxQJUmSVComqJIkSQVyDGo+E1RJkiSVigWqJEmSSsVH/JIkSQXyRf35TFAlSZJUKqVNUO9/d1RTd0Faas/c/JWm7oK0TAwe9n5Td0FaJkb/uKl74CSphjBBlSRJUqmUNkGVJElaETkGNZ8JqiRJkkrFBFWSJKlAjkHNZ4IqSZKkUjFBlSRJKpBjUPOZoEqSJKlUTFAlSZIKZDqYz89IkiRJpWKCKkmSVKBwGn8uE1RJkiSVigWqJElSgaLgJbc/EZ0j4saIeCkiXoyIL0RE14i4JyJeyX52yfaNiLggIsZExLMRsUnVeQ7J9n8lIg5Zms/IAlWSJKl5+z3wj5TSAGAj4EXgJ8C9KaX+wL3ZOsAeQP9sGQr8ESAiugKnA1sCWwCnzytql4QFqiRJUjMVEZ2A7YBLAVJKs1NKU4BBwBXZblcAg7PfBwFXpopHgc4RsRqwG3BPSmlSSmkycA+w+5L2ywJVkiSpQBFR9DI0IkZVLUOrutMXmABcFhFPRcRfIqIdsEpKaXy2z7vAKtnvPYG3q44fm7XV175EnMUvSZK0AkspDQOG1bO5FtgEODqlNDIifs//HufPOz5FRGrkbn6KCaokSVKBSjZJaiwwNqU0Mlu/kUrB+l726J7s5/vZ9nFA76rje2Vt9bUvEQtUSZKkZiql9C7wdkSsmzXtDIwGbgXmzcQ/BLgl+/1W4OBsNv9WwNRsKMBdwK4R0SWbHLVr1rZEfMQvSZJUoBK+qP9o4OqIaAm8BhxGJcS8PiKGAG8C+2f7jgD2BMYAM7J9SSlNioizgMez/c5MKU1a0g5ZoEqSJDVjKaWngc0WsmnnheybgKPqOc9wYPiy6JMFqiRJUoFKl5+WkGNQJUmSVComqJIkSQUKM9RcJqiSJEkqFRNUSZKkAtUYoOYyQZUkSVKpmKBKkiQVyDGo+UxQJUmSVComqJIkSQUq3xdJlY8JqiRJkkrFAlWSJEml4iN+SZKkAjlJKp8JqiRJkkrFBFWSJKlATpLKZ4IqSZKkUjFBlSRJKpBjUPOZoEqSJKlUTFAlSZIK5BjUfCaokiRJKhUTVEmSpAI5BjWfCaokSZJKxQRVkiSpQKaD+fyMJEmSVComqJIkSQUKp/HnMkGVJElSqZigSpIkFcoENY8JqiRJkkrFAlWSJEml4iN+SZKkAvmAP58JqiRJkkrFBFWSJKlAvmYqnwmqJEmSSsUEVZIkqVAmqHlMUCVJklQqJqiSJEkFMj/NZ4IqSZKkUjFBlSRJKlCYoeYyQZUkSVKpmKBKkiQVyfeg5jJBlSRJUqmYoEqSJBXI/DSfCaokSZJKxQRVkiSpUGaoeUxQJUmSVCoWqJIkSSoVH/FLkiQVyBf15zNBlSRJUqmYoEqSJBXI9/TnM0GVJElSqZigSpIkFcoINY8JqiRJkkrFBFWSJKlAzuLPZ4IqSZKkUjFBlSRJKpD5aT4TVEmSpGYuIlpExFMRcXu23jciRkbEmIi4LiJaZu2tsvUx2fY1q85xUtb+ckTstjT9sUCVJEkqUkSxS8McA7xYtX4OcH5KaW1gMjAkax8CTM7az8/2IyIGAgcA6wO7AxdHRIsl/YgsUCVJkpqxiOgF7AX8JVsPYCfgxmyXK4DB2e+DsnWy7Ttn+w8Crk0pzUopvQ6MAbZY0j5ZoEqSJBUoiv6/iKERMapqGbpAl34HnADMzda7AVNSSnXZ+ligZ/Z7T+BtgGz71Gz/+e0LOWaxOUlKkiRpBZZSGgYMW9i2iNgbeD+l9ERE7FBoxxbBAlWSJKlAJXsP6jbAvhGxJ9Aa6Aj8HugcEbVZStoLGJftPw7oDYyNiFqgEzCxqn2e6mMWm4/4JUmSmqmU0kkppV4ppTWpTHL6V0rpG8B9wH7ZbocAt2S/35qtk23/V0opZe0HZLP8+wL9gceWtF8mqJIkSVrQicC1EfFz4Cng0qz9UuCqiBgDTKJS1JJSeiEirgdGA3XAUSmlOUt6cQtUSZIkkVK6H7g/+/01FjILP6X0MfC1eo4/Gzh7WfTFR/ySJEkqlUZPUCNiFWDzbPWxlNL7jX1NSZKksoqGvzy/2WrUBDUi9qcyQPZrwP7AyIjYb9FHSZIkqTlr7AT1FGDzealpRPQA/sn/vplAjWDGRzO47jdXM/6N8RBw4I++yYuPvcBz/36WqAk6dO7AQSd8i07dOzPqn49x77X3ANCqTSu+duwB9FyrFwAvPvYCN110I2nuXLbacxu+dOCuTXlbakZmz5rNT77zUz6Z/Qlz5sxhm52/wDeGHkBKiav++Df+fe9/qGlRwx5f3Y19v74X9//jQf7vyr+TErRp24YjTxxK33XWrPc8UmP6+e4D2L5fdybNmM2gyyuTmI/epi879e9BSomJMz7h5BGjmTB9Nodv3oe9B64CQIsI+nVrxxcveoipH1fej14TcMO3Nue9j2Zx5E3PAnDWbgNYf9UORARvTJrBKXe+yIxPlnguipqECWqeqLwZoJFOHvFcSmnDqvUa4JnqtvrcOfafjdexFdzVv7qSfhuuxRf22oa6T+qYPWs2NRG0btcGgAduuo/33nyX/X94IK+/8Bqr9FmVth3aMnrkC/zjyjs47qITmDtnLmcfcgbfO/doOvfozG+PPJeDTzmMVddcrYnvbvmyVodVm7oLy6WUEh/P/Jg2bdtQV1fHiUecyhHHHc7YN8by7KjnOfb071NTU8OUSVPp3LUTLz77Er3X7EX7ju0Z9ciTXPPn6znvsl/Ve54BG67T1Le43Bk8zNFZDbVpr87MmF3Hr/YcOL9AbdeyBdNnV4rIb27Si7W6teOMe17+1HE7rNWNgzftw+HXPzW/7ZDNerP+Kh1o36p2foFafa4TdlybSdM/4S+PvVnEra0QRv94pyavDl+e+nyhNc66nTZo8nteXI09SeofEXFXRBwaEYcCdwB3NvI1m7WZH83k1efGsNWeWwNQu1Itbdu3nV+cAsz+ePb8P976rt+Pth3aArDmwL5MnTAFgDdfeoPuPXvQffXu1K5Uy8Y7bspzjzxb7M2o2YoI2rSt/DdbVzeHuro6ImDE/93FAd/+GjU1lX+6OnftBMB6nxtA+47tARiwwTp88P7ERZ5HakxPjJ0yPwGdZ15BCdBmpRYkPluf7DlgFUa89N789VXat2L7ft34v+fG13uu1rU1Cz2Xyi0KXpZHjfqIP6X044j4CvDFrGlYSunvjXnN5m7iux/QvlN7/nbuVbzz2jh69+/Dl4/aj1ZtWnHHpbfy+D0jad2uDd8/75jPHPvonY+w3hbrAzD1gyl06dFl/rbOPTrz5otvFHUbEnPmzOGHB5/A+LHvstd+u7PuBuvw7th3+f/27j3cqrrO4/j7G4ooJoeb5A3RJBVt8gIiJea91Eq7+oyNmV0oc7w8Wmk1T5mNlTGmNU4UmVmjEzPOaJmXjPCGmldAQBBQUVETUQgV04TznT/2AvZBOFuRvfbi8H7x7Ie11+W3fns/6znndz6/9futieNv586b72aL3lvwhTM+w9YDt+5w3B+vnsDeI/bstBypFU7db0c+tNvbePGVpXz6vyd32NZjo7cwcoe+nDth9op1Zx00mH+75WF6du/2mrLOff+ujNyxLw8/t4Qf3PRQ0+sula3Zg6TOy8wrM/P04nVVRJzXyf6jIuLeiLj3+suvbWbVuqz2Ze08MWce7/nQSL7ys6/RvUd3Joz7IwBHfvZDnD3uXPY+eBgTf3tLh+PmTJ7NndffwQc/f1Qrqi29Rrdu3fjx5efzy2vGMnvGHB57+HFefXUp3TfpzgW//gHvO/oQfvSdn3Q4Zuq90xh/9QQ+/c/HdVqO1Ao/uu0RDv7ZHVwzcz6f3GvbDtsOeHs/Jj25eEXy+t4d+7Lwpb8zY/4Lqy3rG3+YyQFjbuOR55Zw+C4Dml53rVtR8r/1UbO7+A9dzbrD17RzZo7NzKGZOfTwTx7ZxGp1XW392+jVv41Bu+4AwLv235Mn5szrsM/Qg4dx/8QpK94/9fCTjDv/cj53zhfo2avWTdqrXxuLFixasc9fF/yVXv3aSvgEUkebv7Un79x7d+7782T6btmHEQcMB2DEAcN59KGV993NnfMo/37uGP5l9Fls0fbWTsuRWumaGU9z6OD+HdYdsWvH7v29tunFgTv1Y/yoEZz/wd0YPrA35x05pMMx7QnXPfgMh76jY1lSV9CUBmpEnBgR04CdI2Jq3Wsu4I2MTbRFn1707t+b+fNqP+hmT57FgO3fxoInVg5wmHbHVAZsV/uLe9H8hVxy9lj+6WvHs+V2K/8KH7jL9jz75DM895dnWfrqUibfdB+7v7vh2DZpnVi8aDEvvrAEgFdefoUpd01l2+23Yd/37sO0+6YDMH3SA2w9sDZo75mnF/C9M0dz+rdPYZvtt25YjlS27dtWjgM4aKf+PLLwpRXvN+/ejWHbtnHjQwtWrLtg4iMc9NM7OHTsnznj9w9w1+OLOPPaGQAM7FBWP+bWlaX1RES5r/VQs+5B/S9qg6G+B5xVt/6FzFzYpHOq8JGTP85l372Upa8upe9W/Tj2q8cx7vzLeWbefCKCPgP68PHT/hGAG/7zepY8v4QrfjQOqHWHnjHmTLp168ZHT/4EPz3zP2hvb2f44SPYatDWnZ1WWmcWPruIC799Ee3ty2hvT/Y75N3sM3IoQ/bYlfO/eSG/+8019Ni0B6d840sAjLv4Cp5f/AJjzvs5ULuOL/j1D9ZYjtRMoz+wG/ts10bbphtz4xffzUW3z2X/HfuyQ+/NaAeeWvwy3x7/4Ir9Dxncn9sfXcjfXm1vWHYA3z1iVzbvvhEBzFrw4mtmA5C6gqZMMxURfTrb/noaqU4zpa7AaabUVTjNlLqKKkwz9dDzM0pt4+y0xZCWf+Y3qlkJ6n2wYt6LWM3yjk06ryRJktZzTWmgZuYOy5eLNHUw0KMZ55IkSVqfrK8j68vU1HlQI+JzwKnAtsAUYF/gDuDgZp5XkiRJ669mTzN1KjAMeCwzDwT2BBY3+ZySJEkV5rOkGml2A/XlzHwZICI2ycwHgZ2bfE5JkiStx5raxQ88ERFtwG+B8RGxCHiswTGSJEnagDW1gZqZHy4Wz46Im4BewB+aeU5JkqQqW0/nzi9VsxPUFTLzlsZ7SZIkaUNXWgNVkiRJsL4OXCpTswdJSZIkSW+ICaokSVKJnKi/MRNUSZIkVYoJqiRJUolMUBszQZUkSVKlmKBKkiSVyQC1IRNUSZIkVYoJqiRJUom8B7UxE1RJkiRVigmqJElSiUxQGzNBlSRJUqWYoEqSJJXJALUhE1RJkiRVig1USZIkVYpd/JIkSSVykFRjJqiSJEmqFBNUSZKkEpmgNmaCKkmSpEoxQZUkSSqR+WljJqiSJEmqFBNUSZKkMoUZaiMmqJIkSaoUE1RJkqQSOYq/MRNUSZIkVYoJqiRJUonMTxszQZUkSVKlmKBKkiSVyVH8DZmgSpIkqVJMUCVJkkrkKP7GTFAlSZJUKTZQJUmSVCl28UuSJJXIDv7GTFAlSZJUKTZQJUmSShQl/+u0LhHbRcRNETEjIh6IiFOL9X0iYnxEzCn+712sj4j4cUQ8FBFTI2KvurKOL/afExHHv5nvyAaqJEnShmspcEZmDgH2BU6KiCHAWcCEzBwMTCjeAxwODC5eo4AxUGvQAt8ChgP7AN9a3qhdGzZQJUmSyhQlvzqRmX/JzEnF8gvATGAb4CjgV8VuvwKOLpaPAn6dNXcCbRGxFfA+YHxmLszMRcB44P1r8/WADVRJkqQuLSJGRcS9da9Ra9hvELAncBcwIDP/Umx6GhhQLG8DzKs77Ili3ZrWrxVH8UuSJJWo7In6M3MsMLazfSJic+D/gNMy8/moexxrZmZEZHNr2ZEJqiRJ0gYsIjam1ji9PDOvLFbPL7ruKf5/plj/JLBd3eHbFuvWtH6t2ECVJEkqUcVG8QfwC2BmZv6wbtPVwPKR+McDv6tb/6liNP++wOLiVoAbgMMioncxOOqwYt1asYtfkiRpw/Ue4DhgWkRMKdZ9Hfg+8D8R8VngMeATxbbrgCOAh4CXgBMAMnNhRHwHuKfY75zMXLi2lbKBKkmStIHKzNtY0i8TFwAAB3xJREFU81j/g1ezfwInraGsS4BL1kW97OKXJElSpZigSpIklah+hLxWzwRVkiRJlWKCKkmSVKKy50FdH5mgSpIkqVJsoEqSJKlS7OKXJEkqkR38jZmgSpIkqVJMUCVJksrkNFMNmaBKkiSpUkxQJUmSSuQ0U42ZoEqSJKlSTFAlSZJKZH7amAmqJEmSKsUEVZIkqUTeg9qYCaokSZIqxQRVkiSpTM6D2pAJqiRJkirFBFWSJKlE5qeNmaBKkiSpUkxQJUmSSuQo/sZMUCVJklQpNlAlSZJUKXbxS5IklclpphoyQZUkSVKlmKBKkiSVyPy0MRNUSZIkVYoJqiRJUomcZqoxE1RJkiRVigmqJElSiUxQGzNBlSRJUqWYoEqSJJXJALUhE1RJkiRVigmqJElSibwHtTETVEmSJFVKZGar66AWiYhRmTm21fWQ3iyvZXUVXstSjQnqhm1UqysgrSNey+oqvJYlbKBKkiSpYmygSpIkqVJsoG7YvM9JXYXXsroKr2UJB0lJkiSpYkxQJUmSVCk2UCVJklQpNlC7qIgYFBHT38D+50TEIc2sk1SWiLg5IoYWy9dFRFur6yStSUQ8GhH9IqItIr7U6vpIVWADVQBk5jcz80+troe0rmXmEZn511bXQ3od2gAbqBI2ULu6jSLi8oiYGRH/GxGbRcQ3I+KeiJgeEWMjIgAi4tKI+FixfHBETI6IaRFxSURs0tqPoQ1Bkfo/WFyLs4tr95CIuD0i5kTEPhHRs7gm7y6u0aOKYzeNiHHFtX4VsGlduY9GRL9i+fTi2p8eEae16KNqAxYRv42I+yLigYhYdVL+7wNvj4gpETE6akYX1+u0iDimFXWWWsEGate2M/CTzNwVeJ7aX+YXZeawzNyd2i/xD9QfEBE9gEuBYzLzncBGwIml1lobsp2A84FditexwH7Al4GvA98AbszMfYADgdER0ZPaNfpSca1/C9h71YIjYm/gBGA4sC/w+YjYs+mfSOroM5m5NzAUOCUi+tZtOwt4ODP3yMyvAB8B9gDeBRxC7XrfqvQaSy1gA7Vrm5eZtxfLl1H7RX9gRNwVEdOAg4DdVjlmZ2BuZs4u3v8K2L+U2kq1a29aZrYDDwATsjYX3jRgEHAYcFZETAFuBnoAA6ldo5cBZOZUYOpqyt4PuCozl2Tmi8CVwMjmfhzpNU6JiPuBO4HtgMGd7Lsf8JvMXJaZ84FbgGEl1FFquY1aXQE11aqT3CbwE2BoZs6LiLOp/YKXquKVuuX2uvft1H5eLQM+mpmz6g8q7lSRKi0iDqCWhI7IzJci4mb8GSytlglq1zYwIkYUy8cCtxXLz0bE5sDHVnPMLGBQROxUvD+O2l/tUhXcAJxcd+/08i76W6ld40TE7sA/rObYicDRxb3YPYEPF+uksvQCFhWN012o3WpS7wXgrXXvJwLHRES3iOhPrafg7nKqKrWWCWrXNgs4KSIuAWYAY4DewHTgaeCeVfbPzHw5Ik4AroiIjYp9flpinaXOfAe4EJgaEW8B5lK7j3oM8MuImAnMBO5b9cDMnBQRl7LyF/zFmTm5lFpLNX8Avlhcp7OodfOvkJnPFYMCpwPXA18FRgD3U+sB+2pmPl1ynaWW8FGnAiAifg/8MDNvanVdJEnShs0uflEkrJux8hYASZKkljFBlSRJUqWYoEqSJKlSbKBKkiSpUmygSpIkqVJsoEoqRUQsK54xPj0iroiIzd5EWZdGxMeK5YsjYkgn+54dEV9e23NJkspnA1VSWf5WPGN8d+DvwBfrNxbz7r5hmfm5zJyxLiooSaoGG6iSWmEisFNEHBAREyPiamBG8cSc0RFxT0RMjYgvAETNRRExKyL+BGy5vKCIuDkihhbL74+ISRFxf0RMqDvfkGK/RyLilLpjTy8S3ekRcVqxrmdEXFuUMT0ijinjC5EkreSTpCSVqkhKD6f2VB2AvYDdM3NuRIwCFmfmsIjYBLg9Iv4I7AnsDAwBBlB7Mtolq5TbH/g5sH9RVp+6zbsAB1J7jOSsiBhD7XGoJwDDgQDuiohbgB2BpzLzyKLcXuv8S5AkdcoEVVJZNo2IKcC9wOPAL4r1d2fm3GL5MOBTxX53AX2BwdSeQf6bzFyWmU8BN66m/H2BW5eXlZkL67Zdm5mvZOazwDPUGrn7AVdl5pLMfBG4EhgJTAMOjYjzImJkZi5eZ9+AJOl1MUGVVJa/ZeYe9SsiAmBJ/Srg5My8YZX9jniT536lbnkZnfzsy8zZEbEXcATwrxExITPPeZPnlyS9ASaokqrkBuDEiNgYICLeERE9gVuBY4p7VLei1l2/qjuB/SNih+LYPqvZp95E4OiI2Kw4x4eBiRGxNfBSZl4GjKZ2C4IkqUQmqJKq5GJgEDApavHqAuBo4CrgIGr3nj4O/HnVAzNzQXEP65UR8RZqXfmHrulEmTkpIi4F7l5+7sycHBHvA0ZHRDvwKnDiOvpskqTXKTKz1XWQJEmSVrCLX5IkSZViA1WSJEmVYgNVkiRJlWIDVZIkSZViA1WSJEmVYgNVkiRJlWIDVZIkSZXy//7ORtz3vasNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas de clasificación\n",
            "\n",
            "Accuracy: 0.6928990491604289\n",
            "Recall: 0.6928990491604289\n",
            "F1 score: 0.6931316050718525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos cómo performa con los datos de test."
      ],
      "metadata": {
        "id": "G4RvofRFMvVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clasificar_propiedad(best_model, x_test_clasificacion)\n",
        "graficar_matriz_de_confusion(y_test_clasificacion, y_pred, outputs.keys())\n",
        "imprimir_metricas_de_clasificacion(y_test_clasificacion, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "oqdRIRxkysR0",
        "outputId": "c411218b-a175-4e57-9eb3-165e0a2bda24"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540/540 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas de clasificación\n",
            "\n",
            "Accuracy: 0.6342565766600997\n",
            "Recall: 0.6342565766600997\n",
            "F1 score: 0.6340227995538984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión"
      ],
      "metadata": {
        "id": "gaRq38NGrfKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos el modelo."
      ],
      "metadata": {
        "id": "O56w4FZUQBxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_in = x_train_regresion.shape[1]\n",
        "d_out = 1"
      ],
      "metadata": {
        "id": "k_wFdEnSQpR3"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Dense(\n",
        "      hp.Int('units', min_value=32, max_value=512, step=16),\n",
        "      activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]), input_shape=(d_in,)))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(d_out))\n",
        "  learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-1, sampling=\"log\")\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
        "  loss = 'mse', \n",
        "  metrics = ['mse'],)\n",
        "  return model"
      ],
      "metadata": {
        "id": "_-UZPWAIQRdF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buscamos los mejores hiperparámetros."
      ],
      "metadata": {
        "id": "u3R-mtsiRg2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='loss',\n",
        "    max_trials=10,\n",
        "    project_name=\"Regresion\",\n",
        "    overwrite=True)"
      ],
      "metadata": {
        "id": "KbZTbxwrRgeF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
        "tuner.search(x_train_clasificacion, y_train_clasificacion, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
        "best_model = tuner.get_best_models()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0WuHODGRjG5",
        "outputId": "d0f828bc-c446-4837-a5bb-6080c9edf391"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 29s]\n",
            "loss: 0.5874912738800049\n",
            "\n",
            "Best loss So Far: 0.587153971195221\n",
            "Total elapsed time: 00h 03m 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos los mejores hiperparámetros encontrados y entrenamos nuevamente al modelo."
      ],
      "metadata": {
        "id": "M8_KRkd_R6Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "best_hps.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vGCzYG2R5k7",
        "outputId": "0418fd91-6849-4342-cfaf-e7d3be9810b6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 224, 'activation': 'relu', 'lr': 0.00010700549249923322}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = build_model(best_hps)\n",
        "best_model.fit(x=x_train_regresion, y=y_train_regresion, epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xxdh_VtSB_1",
        "outputId": "fd9afc83-b5cd-4677-ab4a-c8e6b307cb45"
      },
      "execution_count": 70,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 32732413952.0000 - mse: 32732413952.0000\n",
            "Epoch 2/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 6488169984.0000 - mse: 6488169984.0000\n",
            "Epoch 3/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 3065523968.0000 - mse: 3065523968.0000\n",
            "Epoch 4/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2878243584.0000 - mse: 2878243584.0000\n",
            "Epoch 5/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2804150016.0000 - mse: 2804150016.0000\n",
            "Epoch 6/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2758620160.0000 - mse: 2758620160.0000\n",
            "Epoch 7/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2727923712.0000 - mse: 2727923712.0000\n",
            "Epoch 8/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2705176320.0000 - mse: 2705176320.0000\n",
            "Epoch 9/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2687800832.0000 - mse: 2687800832.0000\n",
            "Epoch 10/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2673324288.0000 - mse: 2673324288.0000\n",
            "Epoch 11/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2661199616.0000 - mse: 2661199616.0000\n",
            "Epoch 12/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2651013888.0000 - mse: 2651013888.0000\n",
            "Epoch 13/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2642069248.0000 - mse: 2642069248.0000\n",
            "Epoch 14/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2634811392.0000 - mse: 2634811392.0000\n",
            "Epoch 15/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 2628414976.0000 - mse: 2628414976.0000\n",
            "Epoch 16/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2622315264.0000 - mse: 2622315264.0000\n",
            "Epoch 17/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2616353280.0000 - mse: 2616353280.0000\n",
            "Epoch 18/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 2611685120.0000 - mse: 2611685120.0000\n",
            "Epoch 19/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 2606664448.0000 - mse: 2606664448.0000\n",
            "Epoch 20/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2603040000.0000 - mse: 2603040000.0000\n",
            "Epoch 21/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 2598931968.0000 - mse: 2598931968.0000\n",
            "Epoch 22/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2595731712.0000 - mse: 2595731712.0000\n",
            "Epoch 23/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2592449280.0000 - mse: 2592449280.0000\n",
            "Epoch 24/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2589044224.0000 - mse: 2589044224.0000\n",
            "Epoch 25/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 2586116608.0000 - mse: 2586116608.0000\n",
            "Epoch 26/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 2583699712.0000 - mse: 2583699712.0000\n",
            "Epoch 27/500\n",
            "2163/2163 [==============================] - 5s 2ms/step - loss: 2580941568.0000 - mse: 2580941568.0000\n",
            "Epoch 28/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2579114752.0000 - mse: 2579114752.0000\n",
            "Epoch 29/500\n",
            "2163/2163 [==============================] - 5s 3ms/step - loss: 2576287488.0000 - mse: 2576287488.0000\n",
            "Epoch 30/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2574503680.0000 - mse: 2574503680.0000\n",
            "Epoch 31/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2571964416.0000 - mse: 2571964416.0000\n",
            "Epoch 32/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2569635072.0000 - mse: 2569635072.0000\n",
            "Epoch 33/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2568297984.0000 - mse: 2568297984.0000\n",
            "Epoch 34/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2566500864.0000 - mse: 2566500864.0000\n",
            "Epoch 35/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2564893952.0000 - mse: 2564893952.0000\n",
            "Epoch 36/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2563148032.0000 - mse: 2563148032.0000\n",
            "Epoch 37/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2561884416.0000 - mse: 2561884416.0000\n",
            "Epoch 38/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2559502848.0000 - mse: 2559502848.0000\n",
            "Epoch 39/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2558888448.0000 - mse: 2558888448.0000\n",
            "Epoch 40/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2557254400.0000 - mse: 2557254400.0000\n",
            "Epoch 41/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2555282944.0000 - mse: 2555282944.0000\n",
            "Epoch 42/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2554207232.0000 - mse: 2554207232.0000\n",
            "Epoch 43/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2552147968.0000 - mse: 2552147968.0000\n",
            "Epoch 44/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2551307264.0000 - mse: 2551307264.0000\n",
            "Epoch 45/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2549370112.0000 - mse: 2549370112.0000\n",
            "Epoch 46/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2548667648.0000 - mse: 2548667648.0000\n",
            "Epoch 47/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2547274496.0000 - mse: 2547274496.0000\n",
            "Epoch 48/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2545530624.0000 - mse: 2545530624.0000\n",
            "Epoch 49/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2544046080.0000 - mse: 2544046080.0000\n",
            "Epoch 50/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2543001088.0000 - mse: 2543001088.0000\n",
            "Epoch 51/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2541800704.0000 - mse: 2541800704.0000\n",
            "Epoch 52/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2540523264.0000 - mse: 2540523264.0000\n",
            "Epoch 53/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2539549184.0000 - mse: 2539549184.0000\n",
            "Epoch 54/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2537867008.0000 - mse: 2537867008.0000\n",
            "Epoch 55/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2536996864.0000 - mse: 2536996864.0000\n",
            "Epoch 56/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2535478784.0000 - mse: 2535478784.0000\n",
            "Epoch 57/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2533908736.0000 - mse: 2533908736.0000\n",
            "Epoch 58/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2533269248.0000 - mse: 2533269248.0000\n",
            "Epoch 59/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2531567872.0000 - mse: 2531567872.0000\n",
            "Epoch 60/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2530421504.0000 - mse: 2530421504.0000\n",
            "Epoch 61/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2528589312.0000 - mse: 2528589312.0000\n",
            "Epoch 62/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2527364608.0000 - mse: 2527364608.0000\n",
            "Epoch 63/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2526354688.0000 - mse: 2526354688.0000\n",
            "Epoch 64/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2525059840.0000 - mse: 2525059840.0000\n",
            "Epoch 65/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2523678208.0000 - mse: 2523678208.0000\n",
            "Epoch 66/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2522267392.0000 - mse: 2522267392.0000\n",
            "Epoch 67/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2521103872.0000 - mse: 2521103872.0000\n",
            "Epoch 68/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2519354368.0000 - mse: 2519354368.0000\n",
            "Epoch 69/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2517817088.0000 - mse: 2517817088.0000\n",
            "Epoch 70/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2516071424.0000 - mse: 2516071424.0000\n",
            "Epoch 71/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2514662656.0000 - mse: 2514662656.0000\n",
            "Epoch 72/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2513143552.0000 - mse: 2513143552.0000\n",
            "Epoch 73/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 2511861760.0000 - mse: 2511861760.0000\n",
            "Epoch 74/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2510546688.0000 - mse: 2510546688.0000\n",
            "Epoch 75/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2508431360.0000 - mse: 2508431360.0000\n",
            "Epoch 76/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2506638080.0000 - mse: 2506638080.0000\n",
            "Epoch 77/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2504494336.0000 - mse: 2504494336.0000\n",
            "Epoch 78/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2502560256.0000 - mse: 2502560256.0000\n",
            "Epoch 79/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2501280000.0000 - mse: 2501280000.0000\n",
            "Epoch 80/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2499499264.0000 - mse: 2499499264.0000\n",
            "Epoch 81/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2497174272.0000 - mse: 2497174272.0000\n",
            "Epoch 82/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2495312128.0000 - mse: 2495312128.0000\n",
            "Epoch 83/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2492897024.0000 - mse: 2492897024.0000\n",
            "Epoch 84/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2490497792.0000 - mse: 2490497792.0000\n",
            "Epoch 85/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2488095744.0000 - mse: 2488095744.0000\n",
            "Epoch 86/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2485402112.0000 - mse: 2485402112.0000\n",
            "Epoch 87/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2483392512.0000 - mse: 2483392512.0000\n",
            "Epoch 88/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2480520448.0000 - mse: 2480520448.0000\n",
            "Epoch 89/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2477408768.0000 - mse: 2477408768.0000\n",
            "Epoch 90/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2475335680.0000 - mse: 2475335680.0000\n",
            "Epoch 91/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2472004864.0000 - mse: 2472004864.0000\n",
            "Epoch 92/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2470129408.0000 - mse: 2470129408.0000\n",
            "Epoch 93/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 2466523648.0000 - mse: 2466523648.0000\n",
            "Epoch 94/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2463677696.0000 - mse: 2463677696.0000\n",
            "Epoch 95/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2459663360.0000 - mse: 2459663360.0000\n",
            "Epoch 96/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2457854976.0000 - mse: 2457854976.0000\n",
            "Epoch 97/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2454249472.0000 - mse: 2454249472.0000\n",
            "Epoch 98/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2451349248.0000 - mse: 2451349248.0000\n",
            "Epoch 99/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2447956480.0000 - mse: 2447956480.0000\n",
            "Epoch 100/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2444744192.0000 - mse: 2444744192.0000\n",
            "Epoch 101/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2441849344.0000 - mse: 2441849344.0000\n",
            "Epoch 102/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2438049536.0000 - mse: 2438049536.0000\n",
            "Epoch 103/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2435214848.0000 - mse: 2435214848.0000\n",
            "Epoch 104/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 2431680512.0000 - mse: 2431680512.0000\n",
            "Epoch 105/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2428575488.0000 - mse: 2428575488.0000\n",
            "Epoch 106/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2424966144.0000 - mse: 2424966144.0000\n",
            "Epoch 107/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2421763328.0000 - mse: 2421763328.0000\n",
            "Epoch 108/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2418650368.0000 - mse: 2418650368.0000\n",
            "Epoch 109/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2415320576.0000 - mse: 2415320576.0000\n",
            "Epoch 110/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2411934720.0000 - mse: 2411934720.0000\n",
            "Epoch 111/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2408559616.0000 - mse: 2408559616.0000\n",
            "Epoch 112/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2405138176.0000 - mse: 2405138176.0000\n",
            "Epoch 113/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2401988352.0000 - mse: 2401988352.0000\n",
            "Epoch 114/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2398920192.0000 - mse: 2398920192.0000\n",
            "Epoch 115/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2396034816.0000 - mse: 2396034816.0000\n",
            "Epoch 116/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2392830976.0000 - mse: 2392830976.0000\n",
            "Epoch 117/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2390137856.0000 - mse: 2390137856.0000\n",
            "Epoch 118/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2387352064.0000 - mse: 2387352064.0000\n",
            "Epoch 119/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2384671744.0000 - mse: 2384671744.0000\n",
            "Epoch 120/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2381797120.0000 - mse: 2381797120.0000\n",
            "Epoch 121/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2378999808.0000 - mse: 2378999808.0000\n",
            "Epoch 122/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2376595968.0000 - mse: 2376595968.0000\n",
            "Epoch 123/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2373659648.0000 - mse: 2373659648.0000\n",
            "Epoch 124/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2371530752.0000 - mse: 2371530752.0000\n",
            "Epoch 125/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2368811008.0000 - mse: 2368811008.0000\n",
            "Epoch 126/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2366212352.0000 - mse: 2366212352.0000\n",
            "Epoch 127/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2362543360.0000 - mse: 2362543360.0000\n",
            "Epoch 128/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2361534976.0000 - mse: 2361534976.0000\n",
            "Epoch 129/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2358573056.0000 - mse: 2358573056.0000\n",
            "Epoch 130/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2356213504.0000 - mse: 2356213504.0000\n",
            "Epoch 131/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2353868800.0000 - mse: 2353868800.0000\n",
            "Epoch 132/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2351515904.0000 - mse: 2351515904.0000\n",
            "Epoch 133/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2349476352.0000 - mse: 2349476352.0000\n",
            "Epoch 134/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2346836480.0000 - mse: 2346836480.0000\n",
            "Epoch 135/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2345253888.0000 - mse: 2345253888.0000\n",
            "Epoch 136/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2343099648.0000 - mse: 2343099648.0000\n",
            "Epoch 137/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2341102592.0000 - mse: 2341102592.0000\n",
            "Epoch 138/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2338604544.0000 - mse: 2338604544.0000\n",
            "Epoch 139/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2336492800.0000 - mse: 2336492800.0000\n",
            "Epoch 140/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2334276608.0000 - mse: 2334276608.0000\n",
            "Epoch 141/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2332720640.0000 - mse: 2332720640.0000\n",
            "Epoch 142/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2330574336.0000 - mse: 2330574336.0000\n",
            "Epoch 143/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2328431104.0000 - mse: 2328431104.0000\n",
            "Epoch 144/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2325844992.0000 - mse: 2325844992.0000\n",
            "Epoch 145/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2323933696.0000 - mse: 2323933696.0000\n",
            "Epoch 146/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2323211776.0000 - mse: 2323211776.0000\n",
            "Epoch 147/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2321231616.0000 - mse: 2321231616.0000\n",
            "Epoch 148/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2319376640.0000 - mse: 2319376640.0000\n",
            "Epoch 149/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2317438208.0000 - mse: 2317438208.0000\n",
            "Epoch 150/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2316134144.0000 - mse: 2316134144.0000\n",
            "Epoch 151/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2314102272.0000 - mse: 2314102272.0000\n",
            "Epoch 152/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2311626240.0000 - mse: 2311626240.0000\n",
            "Epoch 153/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2310930688.0000 - mse: 2310930688.0000\n",
            "Epoch 154/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2308738048.0000 - mse: 2308738048.0000\n",
            "Epoch 155/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2307095040.0000 - mse: 2307095040.0000\n",
            "Epoch 156/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2305234688.0000 - mse: 2305234688.0000\n",
            "Epoch 157/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2303770112.0000 - mse: 2303770112.0000\n",
            "Epoch 158/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2301957632.0000 - mse: 2301957632.0000\n",
            "Epoch 159/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2300369664.0000 - mse: 2300369664.0000\n",
            "Epoch 160/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2298743040.0000 - mse: 2298743040.0000\n",
            "Epoch 161/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2297137664.0000 - mse: 2297137664.0000\n",
            "Epoch 162/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2295391488.0000 - mse: 2295391488.0000\n",
            "Epoch 163/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2293946624.0000 - mse: 2293946624.0000\n",
            "Epoch 164/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2291612928.0000 - mse: 2291612928.0000\n",
            "Epoch 165/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2289646592.0000 - mse: 2289646592.0000\n",
            "Epoch 166/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2288915200.0000 - mse: 2288915200.0000\n",
            "Epoch 167/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2287650816.0000 - mse: 2287650816.0000\n",
            "Epoch 168/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2285879040.0000 - mse: 2285879040.0000\n",
            "Epoch 169/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2283743744.0000 - mse: 2283743744.0000\n",
            "Epoch 170/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2282806016.0000 - mse: 2282806016.0000\n",
            "Epoch 171/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2281210368.0000 - mse: 2281210368.0000\n",
            "Epoch 172/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2279241984.0000 - mse: 2279241984.0000\n",
            "Epoch 173/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2277723136.0000 - mse: 2277723136.0000\n",
            "Epoch 174/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2275785984.0000 - mse: 2275785984.0000\n",
            "Epoch 175/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2274328832.0000 - mse: 2274328832.0000\n",
            "Epoch 176/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2273187072.0000 - mse: 2273187072.0000\n",
            "Epoch 177/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2270886656.0000 - mse: 2270886656.0000\n",
            "Epoch 178/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2269403648.0000 - mse: 2269403648.0000\n",
            "Epoch 179/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2267573248.0000 - mse: 2267573248.0000\n",
            "Epoch 180/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2266040320.0000 - mse: 2266040320.0000\n",
            "Epoch 181/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2264138240.0000 - mse: 2264138240.0000\n",
            "Epoch 182/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2262481920.0000 - mse: 2262481920.0000\n",
            "Epoch 183/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2260829952.0000 - mse: 2260829952.0000\n",
            "Epoch 184/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2258974464.0000 - mse: 2258974464.0000\n",
            "Epoch 185/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2256883200.0000 - mse: 2256883200.0000\n",
            "Epoch 186/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2255362304.0000 - mse: 2255362304.0000\n",
            "Epoch 187/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2252989440.0000 - mse: 2252989440.0000\n",
            "Epoch 188/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2251091968.0000 - mse: 2251091968.0000\n",
            "Epoch 189/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2249382656.0000 - mse: 2249382656.0000\n",
            "Epoch 190/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2247369728.0000 - mse: 2247369728.0000\n",
            "Epoch 191/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2244731392.0000 - mse: 2244731392.0000\n",
            "Epoch 192/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2243359232.0000 - mse: 2243359232.0000\n",
            "Epoch 193/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2240570624.0000 - mse: 2240570624.0000\n",
            "Epoch 194/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2239549952.0000 - mse: 2239549952.0000\n",
            "Epoch 195/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2237370112.0000 - mse: 2237370112.0000\n",
            "Epoch 196/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2235218944.0000 - mse: 2235218944.0000\n",
            "Epoch 197/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2232405760.0000 - mse: 2232405760.0000\n",
            "Epoch 198/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2230899968.0000 - mse: 2230899968.0000\n",
            "Epoch 199/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2229107968.0000 - mse: 2229107968.0000\n",
            "Epoch 200/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2227221504.0000 - mse: 2227221504.0000\n",
            "Epoch 201/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2224955904.0000 - mse: 2224955904.0000\n",
            "Epoch 202/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2222689024.0000 - mse: 2222689024.0000\n",
            "Epoch 203/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2220928512.0000 - mse: 2220928512.0000\n",
            "Epoch 204/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2218331392.0000 - mse: 2218331392.0000\n",
            "Epoch 205/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2216781568.0000 - mse: 2216781568.0000\n",
            "Epoch 206/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2214934528.0000 - mse: 2214934528.0000\n",
            "Epoch 207/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2212673792.0000 - mse: 2212673792.0000\n",
            "Epoch 208/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2210515712.0000 - mse: 2210515712.0000\n",
            "Epoch 209/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2208527360.0000 - mse: 2208527360.0000\n",
            "Epoch 210/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2206739456.0000 - mse: 2206739456.0000\n",
            "Epoch 211/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2204417536.0000 - mse: 2204417536.0000\n",
            "Epoch 212/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2202453504.0000 - mse: 2202453504.0000\n",
            "Epoch 213/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2199995648.0000 - mse: 2199995648.0000\n",
            "Epoch 214/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2197742336.0000 - mse: 2197742336.0000\n",
            "Epoch 215/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2196084224.0000 - mse: 2196084224.0000\n",
            "Epoch 216/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2193434880.0000 - mse: 2193434880.0000\n",
            "Epoch 217/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2190644992.0000 - mse: 2190644992.0000\n",
            "Epoch 218/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2188349696.0000 - mse: 2188349696.0000\n",
            "Epoch 219/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2185961728.0000 - mse: 2185961728.0000\n",
            "Epoch 220/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2183688960.0000 - mse: 2183688960.0000\n",
            "Epoch 221/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2181942016.0000 - mse: 2181942016.0000\n",
            "Epoch 222/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2178946560.0000 - mse: 2178946560.0000\n",
            "Epoch 223/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2176656384.0000 - mse: 2176656384.0000\n",
            "Epoch 224/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2174544384.0000 - mse: 2174544384.0000\n",
            "Epoch 225/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2172067840.0000 - mse: 2172067840.0000\n",
            "Epoch 226/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2169718272.0000 - mse: 2169718272.0000\n",
            "Epoch 227/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2167760896.0000 - mse: 2167760896.0000\n",
            "Epoch 228/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2165219584.0000 - mse: 2165219584.0000\n",
            "Epoch 229/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2162918656.0000 - mse: 2162918656.0000\n",
            "Epoch 230/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2160761088.0000 - mse: 2160761088.0000\n",
            "Epoch 231/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2157750784.0000 - mse: 2157750784.0000\n",
            "Epoch 232/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2155457024.0000 - mse: 2155457024.0000\n",
            "Epoch 233/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2153140480.0000 - mse: 2153140480.0000\n",
            "Epoch 234/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2151234304.0000 - mse: 2151234304.0000\n",
            "Epoch 235/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2149476608.0000 - mse: 2149476608.0000\n",
            "Epoch 236/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2147162880.0000 - mse: 2147162880.0000\n",
            "Epoch 237/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2145323520.0000 - mse: 2145323520.0000\n",
            "Epoch 238/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2143689216.0000 - mse: 2143689216.0000\n",
            "Epoch 239/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2141670912.0000 - mse: 2141670912.0000\n",
            "Epoch 240/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2140091264.0000 - mse: 2140091264.0000\n",
            "Epoch 241/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2138448256.0000 - mse: 2138448256.0000\n",
            "Epoch 242/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2136956672.0000 - mse: 2136956672.0000\n",
            "Epoch 243/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2135331968.0000 - mse: 2135331968.0000\n",
            "Epoch 244/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2133418368.0000 - mse: 2133418368.0000\n",
            "Epoch 245/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2132027008.0000 - mse: 2132027008.0000\n",
            "Epoch 246/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2130913664.0000 - mse: 2130913664.0000\n",
            "Epoch 247/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2128594560.0000 - mse: 2128594560.0000\n",
            "Epoch 248/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2127545472.0000 - mse: 2127545472.0000\n",
            "Epoch 249/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2125839232.0000 - mse: 2125839232.0000\n",
            "Epoch 250/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2124123520.0000 - mse: 2124123520.0000\n",
            "Epoch 251/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2122974080.0000 - mse: 2122974080.0000\n",
            "Epoch 252/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2121911296.0000 - mse: 2121911296.0000\n",
            "Epoch 253/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2120468480.0000 - mse: 2120468480.0000\n",
            "Epoch 254/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2118862336.0000 - mse: 2118862336.0000\n",
            "Epoch 255/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2117618176.0000 - mse: 2117618176.0000\n",
            "Epoch 256/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2117063936.0000 - mse: 2117063936.0000\n",
            "Epoch 257/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2115476480.0000 - mse: 2115476480.0000\n",
            "Epoch 258/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2114498688.0000 - mse: 2114498688.0000\n",
            "Epoch 259/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2113769984.0000 - mse: 2113769984.0000\n",
            "Epoch 260/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2112615936.0000 - mse: 2112615936.0000\n",
            "Epoch 261/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2111396224.0000 - mse: 2111396224.0000\n",
            "Epoch 262/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2110364160.0000 - mse: 2110364160.0000\n",
            "Epoch 263/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2109166080.0000 - mse: 2109166080.0000\n",
            "Epoch 264/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2108489600.0000 - mse: 2108489600.0000\n",
            "Epoch 265/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2107309696.0000 - mse: 2107309696.0000\n",
            "Epoch 266/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2106131200.0000 - mse: 2106131200.0000\n",
            "Epoch 267/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2104596608.0000 - mse: 2104596608.0000\n",
            "Epoch 268/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2104349696.0000 - mse: 2104349696.0000\n",
            "Epoch 269/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2103064320.0000 - mse: 2103064320.0000\n",
            "Epoch 270/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2102227456.0000 - mse: 2102227456.0000\n",
            "Epoch 271/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2101116160.0000 - mse: 2101116160.0000\n",
            "Epoch 272/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2100165248.0000 - mse: 2100165248.0000\n",
            "Epoch 273/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2099200640.0000 - mse: 2099200640.0000\n",
            "Epoch 274/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2097852928.0000 - mse: 2097852928.0000\n",
            "Epoch 275/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2097716864.0000 - mse: 2097716864.0000\n",
            "Epoch 276/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2095800832.0000 - mse: 2095800832.0000\n",
            "Epoch 277/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2095388288.0000 - mse: 2095388288.0000\n",
            "Epoch 278/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2094837888.0000 - mse: 2094837888.0000\n",
            "Epoch 279/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2094057216.0000 - mse: 2094057216.0000\n",
            "Epoch 280/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2092701312.0000 - mse: 2092701312.0000\n",
            "Epoch 281/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2091678208.0000 - mse: 2091678208.0000\n",
            "Epoch 282/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2091098752.0000 - mse: 2091098752.0000\n",
            "Epoch 283/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2089991808.0000 - mse: 2089991808.0000\n",
            "Epoch 284/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2088961920.0000 - mse: 2088961920.0000\n",
            "Epoch 285/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2088597120.0000 - mse: 2088597120.0000\n",
            "Epoch 286/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2087990784.0000 - mse: 2087990784.0000\n",
            "Epoch 287/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2086846976.0000 - mse: 2086846976.0000\n",
            "Epoch 288/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2085781888.0000 - mse: 2085781888.0000\n",
            "Epoch 289/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2085000320.0000 - mse: 2085000320.0000\n",
            "Epoch 290/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2084291072.0000 - mse: 2084291072.0000\n",
            "Epoch 291/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2083326208.0000 - mse: 2083326208.0000\n",
            "Epoch 292/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2082906368.0000 - mse: 2082906368.0000\n",
            "Epoch 293/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2082359168.0000 - mse: 2082359168.0000\n",
            "Epoch 294/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2081659904.0000 - mse: 2081659904.0000\n",
            "Epoch 295/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2080017152.0000 - mse: 2080017152.0000\n",
            "Epoch 296/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2079872896.0000 - mse: 2079872896.0000\n",
            "Epoch 297/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2078719616.0000 - mse: 2078719616.0000\n",
            "Epoch 298/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2078270208.0000 - mse: 2078270208.0000\n",
            "Epoch 299/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2077491200.0000 - mse: 2077491200.0000\n",
            "Epoch 300/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2076549888.0000 - mse: 2076549888.0000\n",
            "Epoch 301/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2076395904.0000 - mse: 2076395904.0000\n",
            "Epoch 302/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2075286912.0000 - mse: 2075286912.0000\n",
            "Epoch 303/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2074562048.0000 - mse: 2074562048.0000\n",
            "Epoch 304/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2074218752.0000 - mse: 2074218752.0000\n",
            "Epoch 305/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2073260416.0000 - mse: 2073260416.0000\n",
            "Epoch 306/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2072327552.0000 - mse: 2072327552.0000\n",
            "Epoch 307/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2071856768.0000 - mse: 2071856768.0000\n",
            "Epoch 308/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2070459008.0000 - mse: 2070459008.0000\n",
            "Epoch 309/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2070356992.0000 - mse: 2070356992.0000\n",
            "Epoch 310/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2069599360.0000 - mse: 2069599360.0000\n",
            "Epoch 311/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2069073024.0000 - mse: 2069073024.0000\n",
            "Epoch 312/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2067941632.0000 - mse: 2067941632.0000\n",
            "Epoch 313/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2067634176.0000 - mse: 2067634176.0000\n",
            "Epoch 314/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2066787072.0000 - mse: 2066787072.0000\n",
            "Epoch 315/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2066710912.0000 - mse: 2066710912.0000\n",
            "Epoch 316/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2065188992.0000 - mse: 2065188992.0000\n",
            "Epoch 317/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2064588672.0000 - mse: 2064588672.0000\n",
            "Epoch 318/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2064127744.0000 - mse: 2064127744.0000\n",
            "Epoch 319/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2063104256.0000 - mse: 2063104256.0000\n",
            "Epoch 320/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2062897408.0000 - mse: 2062897408.0000\n",
            "Epoch 321/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2061904640.0000 - mse: 2061904640.0000\n",
            "Epoch 322/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2061803264.0000 - mse: 2061803264.0000\n",
            "Epoch 323/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2060518144.0000 - mse: 2060518144.0000\n",
            "Epoch 324/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2060257792.0000 - mse: 2060257792.0000\n",
            "Epoch 325/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2059518336.0000 - mse: 2059518336.0000\n",
            "Epoch 326/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2058759424.0000 - mse: 2058759424.0000\n",
            "Epoch 327/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2057922816.0000 - mse: 2057922816.0000\n",
            "Epoch 328/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2057270912.0000 - mse: 2057270912.0000\n",
            "Epoch 329/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2057008384.0000 - mse: 2057008384.0000\n",
            "Epoch 330/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2055609216.0000 - mse: 2055609216.0000\n",
            "Epoch 331/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2055638016.0000 - mse: 2055638016.0000\n",
            "Epoch 332/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2054640256.0000 - mse: 2054640256.0000\n",
            "Epoch 333/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2054021248.0000 - mse: 2054021248.0000\n",
            "Epoch 334/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2053634816.0000 - mse: 2053634816.0000\n",
            "Epoch 335/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2052874496.0000 - mse: 2052874496.0000\n",
            "Epoch 336/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2052269696.0000 - mse: 2052269696.0000\n",
            "Epoch 337/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2051739136.0000 - mse: 2051739136.0000\n",
            "Epoch 338/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2051123840.0000 - mse: 2051123840.0000\n",
            "Epoch 339/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2050267392.0000 - mse: 2050267392.0000\n",
            "Epoch 340/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2049518464.0000 - mse: 2049518464.0000\n",
            "Epoch 341/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2049112320.0000 - mse: 2049112320.0000\n",
            "Epoch 342/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2047985024.0000 - mse: 2047985024.0000\n",
            "Epoch 343/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2047634176.0000 - mse: 2047634176.0000\n",
            "Epoch 344/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2047021568.0000 - mse: 2047021568.0000\n",
            "Epoch 345/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2046436608.0000 - mse: 2046436608.0000\n",
            "Epoch 346/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2045575936.0000 - mse: 2045575936.0000\n",
            "Epoch 347/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2045228288.0000 - mse: 2045228288.0000\n",
            "Epoch 348/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2044561536.0000 - mse: 2044561536.0000\n",
            "Epoch 349/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2044165120.0000 - mse: 2044165120.0000\n",
            "Epoch 350/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2043304320.0000 - mse: 2043304320.0000\n",
            "Epoch 351/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2043119232.0000 - mse: 2043119232.0000\n",
            "Epoch 352/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2042302720.0000 - mse: 2042302720.0000\n",
            "Epoch 353/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2041371520.0000 - mse: 2041371520.0000\n",
            "Epoch 354/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2041420544.0000 - mse: 2041420544.0000\n",
            "Epoch 355/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2040527104.0000 - mse: 2040527104.0000\n",
            "Epoch 356/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2039593472.0000 - mse: 2039593472.0000\n",
            "Epoch 357/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2039214336.0000 - mse: 2039214336.0000\n",
            "Epoch 358/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2039300352.0000 - mse: 2039300352.0000\n",
            "Epoch 359/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2038657664.0000 - mse: 2038657664.0000\n",
            "Epoch 360/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2037669760.0000 - mse: 2037669760.0000\n",
            "Epoch 361/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2037539584.0000 - mse: 2037539584.0000\n",
            "Epoch 362/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2036517248.0000 - mse: 2036517248.0000\n",
            "Epoch 363/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2035881984.0000 - mse: 2035881984.0000\n",
            "Epoch 364/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2035748480.0000 - mse: 2035748480.0000\n",
            "Epoch 365/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2034717312.0000 - mse: 2034717312.0000\n",
            "Epoch 366/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2034252800.0000 - mse: 2034252800.0000\n",
            "Epoch 367/500\n",
            "2163/2163 [==============================] - 7s 3ms/step - loss: 2033885568.0000 - mse: 2033885568.0000\n",
            "Epoch 368/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2033089152.0000 - mse: 2033089152.0000\n",
            "Epoch 369/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2033026432.0000 - mse: 2033026432.0000\n",
            "Epoch 370/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2032561280.0000 - mse: 2032561280.0000\n",
            "Epoch 371/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2031345792.0000 - mse: 2031345792.0000\n",
            "Epoch 372/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2031750528.0000 - mse: 2031750528.0000\n",
            "Epoch 373/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2030470656.0000 - mse: 2030470656.0000\n",
            "Epoch 374/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2030168192.0000 - mse: 2030168192.0000\n",
            "Epoch 375/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2029815936.0000 - mse: 2029815936.0000\n",
            "Epoch 376/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2029331712.0000 - mse: 2029331712.0000\n",
            "Epoch 377/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2028473472.0000 - mse: 2028473472.0000\n",
            "Epoch 378/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2028176256.0000 - mse: 2028176256.0000\n",
            "Epoch 379/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2027708160.0000 - mse: 2027708160.0000\n",
            "Epoch 380/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2026744960.0000 - mse: 2026744960.0000\n",
            "Epoch 381/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2026845568.0000 - mse: 2026845568.0000\n",
            "Epoch 382/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2025995520.0000 - mse: 2025995520.0000\n",
            "Epoch 383/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2024545408.0000 - mse: 2024545408.0000\n",
            "Epoch 384/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2024927104.0000 - mse: 2024927104.0000\n",
            "Epoch 385/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2024144640.0000 - mse: 2024144640.0000\n",
            "Epoch 386/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2023972480.0000 - mse: 2023972480.0000\n",
            "Epoch 387/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2022915840.0000 - mse: 2022915840.0000\n",
            "Epoch 388/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2022712064.0000 - mse: 2022712064.0000\n",
            "Epoch 389/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2022108928.0000 - mse: 2022108928.0000\n",
            "Epoch 390/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2021739776.0000 - mse: 2021739776.0000\n",
            "Epoch 391/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2021405184.0000 - mse: 2021405184.0000\n",
            "Epoch 392/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2021406208.0000 - mse: 2021406208.0000\n",
            "Epoch 393/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2020467456.0000 - mse: 2020467456.0000\n",
            "Epoch 394/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2019744256.0000 - mse: 2019744256.0000\n",
            "Epoch 395/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2019272064.0000 - mse: 2019272064.0000\n",
            "Epoch 396/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2018926592.0000 - mse: 2018926592.0000\n",
            "Epoch 397/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2018640512.0000 - mse: 2018640512.0000\n",
            "Epoch 398/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2017386240.0000 - mse: 2017386240.0000\n",
            "Epoch 399/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2017445632.0000 - mse: 2017445632.0000\n",
            "Epoch 400/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2016327552.0000 - mse: 2016327552.0000\n",
            "Epoch 401/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2016413696.0000 - mse: 2016413696.0000\n",
            "Epoch 402/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2016065664.0000 - mse: 2016065664.0000\n",
            "Epoch 403/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2015186432.0000 - mse: 2015186432.0000\n",
            "Epoch 404/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2014348544.0000 - mse: 2014348544.0000\n",
            "Epoch 405/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2013836032.0000 - mse: 2013836032.0000\n",
            "Epoch 406/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2013958656.0000 - mse: 2013958656.0000\n",
            "Epoch 407/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2012827904.0000 - mse: 2012827904.0000\n",
            "Epoch 408/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2011954176.0000 - mse: 2011954176.0000\n",
            "Epoch 409/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2012296704.0000 - mse: 2012296704.0000\n",
            "Epoch 410/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2011863552.0000 - mse: 2011863552.0000\n",
            "Epoch 411/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2011214720.0000 - mse: 2011214720.0000\n",
            "Epoch 412/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2010453632.0000 - mse: 2010453632.0000\n",
            "Epoch 413/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2010195072.0000 - mse: 2010195072.0000\n",
            "Epoch 414/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2008566272.0000 - mse: 2008566272.0000\n",
            "Epoch 415/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2008842880.0000 - mse: 2008842880.0000\n",
            "Epoch 416/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2008287872.0000 - mse: 2008287872.0000\n",
            "Epoch 417/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2007309312.0000 - mse: 2007309312.0000\n",
            "Epoch 418/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2007162752.0000 - mse: 2007162752.0000\n",
            "Epoch 419/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2006625280.0000 - mse: 2006625280.0000\n",
            "Epoch 420/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2005723520.0000 - mse: 2005723520.0000\n",
            "Epoch 421/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2005281792.0000 - mse: 2005281792.0000\n",
            "Epoch 422/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2006061952.0000 - mse: 2006061952.0000\n",
            "Epoch 423/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2004874752.0000 - mse: 2004874752.0000\n",
            "Epoch 424/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2004610304.0000 - mse: 2004610304.0000\n",
            "Epoch 425/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2004032512.0000 - mse: 2004032512.0000\n",
            "Epoch 426/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2002935040.0000 - mse: 2002935040.0000\n",
            "Epoch 427/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2002384128.0000 - mse: 2002384128.0000\n",
            "Epoch 428/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2002178560.0000 - mse: 2002178560.0000\n",
            "Epoch 429/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 2001542016.0000 - mse: 2001542016.0000\n",
            "Epoch 430/500\n",
            "2163/2163 [==============================] - 8s 4ms/step - loss: 2000992896.0000 - mse: 2000992896.0000\n",
            "Epoch 431/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2000921472.0000 - mse: 2000921472.0000\n",
            "Epoch 432/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 2000393600.0000 - mse: 2000393600.0000\n",
            "Epoch 433/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1999758592.0000 - mse: 1999758592.0000\n",
            "Epoch 434/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1999191424.0000 - mse: 1999191424.0000\n",
            "Epoch 435/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1998681984.0000 - mse: 1998681984.0000\n",
            "Epoch 436/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1998474240.0000 - mse: 1998474240.0000\n",
            "Epoch 437/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1998102144.0000 - mse: 1998102144.0000\n",
            "Epoch 438/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1997153792.0000 - mse: 1997153792.0000\n",
            "Epoch 439/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1996696704.0000 - mse: 1996696704.0000\n",
            "Epoch 440/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1996844800.0000 - mse: 1996844800.0000\n",
            "Epoch 441/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1996585472.0000 - mse: 1996585472.0000\n",
            "Epoch 442/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1995675904.0000 - mse: 1995675904.0000\n",
            "Epoch 443/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1994835712.0000 - mse: 1994835712.0000\n",
            "Epoch 444/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1994020736.0000 - mse: 1994020736.0000\n",
            "Epoch 445/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1993544960.0000 - mse: 1993544960.0000\n",
            "Epoch 446/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1993480320.0000 - mse: 1993480320.0000\n",
            "Epoch 447/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1993120512.0000 - mse: 1993120512.0000\n",
            "Epoch 448/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1992767232.0000 - mse: 1992767232.0000\n",
            "Epoch 449/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1992621440.0000 - mse: 1992621440.0000\n",
            "Epoch 450/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1991967104.0000 - mse: 1991967104.0000\n",
            "Epoch 451/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1991883264.0000 - mse: 1991883264.0000\n",
            "Epoch 452/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1991063040.0000 - mse: 1991063040.0000\n",
            "Epoch 453/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1990682368.0000 - mse: 1990682368.0000\n",
            "Epoch 454/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1989977216.0000 - mse: 1989977216.0000\n",
            "Epoch 455/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1989668352.0000 - mse: 1989668352.0000\n",
            "Epoch 456/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1989548928.0000 - mse: 1989548928.0000\n",
            "Epoch 457/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1988149376.0000 - mse: 1988149376.0000\n",
            "Epoch 458/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1988414848.0000 - mse: 1988414848.0000\n",
            "Epoch 459/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1987443968.0000 - mse: 1987443968.0000\n",
            "Epoch 460/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1986937600.0000 - mse: 1986937600.0000\n",
            "Epoch 461/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1986810368.0000 - mse: 1986810368.0000\n",
            "Epoch 462/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1985968512.0000 - mse: 1985968512.0000\n",
            "Epoch 463/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1985556736.0000 - mse: 1985556736.0000\n",
            "Epoch 464/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1985214464.0000 - mse: 1985214464.0000\n",
            "Epoch 465/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1985339136.0000 - mse: 1985339136.0000\n",
            "Epoch 466/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1984574976.0000 - mse: 1984574976.0000\n",
            "Epoch 467/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1983832448.0000 - mse: 1983832448.0000\n",
            "Epoch 468/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1983630976.0000 - mse: 1983630976.0000\n",
            "Epoch 469/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1983239168.0000 - mse: 1983239168.0000\n",
            "Epoch 470/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1982715904.0000 - mse: 1982715904.0000\n",
            "Epoch 471/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1982576896.0000 - mse: 1982576896.0000\n",
            "Epoch 472/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1982456064.0000 - mse: 1982456064.0000\n",
            "Epoch 473/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1981919232.0000 - mse: 1981919232.0000\n",
            "Epoch 474/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1981184128.0000 - mse: 1981184128.0000\n",
            "Epoch 475/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1981062144.0000 - mse: 1981062144.0000\n",
            "Epoch 476/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1979913216.0000 - mse: 1979913216.0000\n",
            "Epoch 477/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1979885696.0000 - mse: 1979885696.0000\n",
            "Epoch 478/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1979623296.0000 - mse: 1979623296.0000\n",
            "Epoch 479/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1978377728.0000 - mse: 1978377728.0000\n",
            "Epoch 480/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1978752000.0000 - mse: 1978752000.0000\n",
            "Epoch 481/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1977744128.0000 - mse: 1977744128.0000\n",
            "Epoch 482/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1977124992.0000 - mse: 1977124992.0000\n",
            "Epoch 483/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1977038464.0000 - mse: 1977038464.0000\n",
            "Epoch 484/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1976687872.0000 - mse: 1976687872.0000\n",
            "Epoch 485/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1975982080.0000 - mse: 1975982080.0000\n",
            "Epoch 486/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1975365376.0000 - mse: 1975365376.0000\n",
            "Epoch 487/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1975362048.0000 - mse: 1975362048.0000\n",
            "Epoch 488/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1974885376.0000 - mse: 1974885376.0000\n",
            "Epoch 489/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1974827392.0000 - mse: 1974827392.0000\n",
            "Epoch 490/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1974362752.0000 - mse: 1974362752.0000\n",
            "Epoch 491/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1972717568.0000 - mse: 1972717568.0000\n",
            "Epoch 492/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1973244160.0000 - mse: 1973244160.0000\n",
            "Epoch 493/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1972879616.0000 - mse: 1972879616.0000\n",
            "Epoch 494/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1972418816.0000 - mse: 1972418816.0000\n",
            "Epoch 495/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1972549120.0000 - mse: 1972549120.0000\n",
            "Epoch 496/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1971509888.0000 - mse: 1971509888.0000\n",
            "Epoch 497/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1971847936.0000 - mse: 1971847936.0000\n",
            "Epoch 498/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1971114112.0000 - mse: 1971114112.0000\n",
            "Epoch 499/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1970574592.0000 - mse: 1970574592.0000\n",
            "Epoch 500/500\n",
            "2163/2163 [==============================] - 6s 3ms/step - loss: 1970048384.0000 - mse: 1970048384.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bf384eb20>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos las predicciones para train y vemos cómo performa."
      ],
      "metadata": {
        "id": "a5V7jYKfSKQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_regresion = best_model.predict(x_train_regresion)\n",
        "imprimir_metricas_de_regresion(y_train_regresion, y_pred_regresion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya_BJ5JoSJ9L",
        "outputId": "13f2a38f-4dcf-4662-a3b4-0f9ded2b26b4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2163/2163 [==============================] - 3s 1ms/step\n",
            "\n",
            "Métricas de regresión\n",
            "\n",
            "El error (mse) de test es: 1965073952.8753333\n",
            "El error (rmse) de test es: 44329.1546600579\n",
            "El score R2 es: 0.8167946762967582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora lo probamos con los datos de test."
      ],
      "metadata": {
        "id": "w9Q7bcEYSplP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_regresion = best_model.predict(x_test_regresion)\n",
        "imprimir_metricas_de_regresion(y_test_regresion, y_pred_regresion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNr_Zq-9SgTF",
        "outputId": "e8dd19d1-71d2-4977-d29a-aa1639ef3727"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540/540 [==============================] - 1s 1ms/step\n",
            "\n",
            "Métricas de regresión\n",
            "\n",
            "El error (mse) de test es: 2076981265.8100636\n",
            "El error (rmse) de test es: 45573.90992453976\n",
            "El score R2 es: 0.8044855283509453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones"
      ],
      "metadata": {
        "id": "1uiqro5uSvVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las redes neuronales son muy poderosas pero el hecho de que su entrenamiento sea lento y la búsqueda de hiperparámetros tenga que ser manual hace que no podamos sacarle el provecho completo.\n",
        "\n",
        "En comparación, XGBoost tiene mejores métricas en menos tiempo, y nos permite hacer una mejor búsqueda de hiperparámetros, por lo que para nuestros objetivos nos sirve más."
      ],
      "metadata": {
        "id": "dWixJlIsSxhW"
      }
    }
  ]
}